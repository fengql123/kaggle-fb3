{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35147,"status":"ok","timestamp":1669560775338,"user":{"displayName":"Feng Qilong","userId":"09603490936825460639"},"user_tz":-480},"id":"6frnPxb0idiN","outputId":"186e1eb8-f3e8-4917-df4d-79601a013211"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n","\u001b[K     |████████████████████████████████| 5.5 MB 24.5 MB/s \n","\u001b[?25hCollecting datasets\n","  Downloading datasets-2.7.1-py3-none-any.whl (451 kB)\n","\u001b[K     |████████████████████████████████| 451 kB 91.0 MB/s \n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 84.5 MB/s \n","\u001b[?25hCollecting optuna\n","  Downloading optuna-3.0.3-py3-none-any.whl (348 kB)\n","\u001b[K     |████████████████████████████████| 348 kB 100.1 MB/s \n","\u001b[?25hCollecting ray\n","  Downloading ray-2.1.0-cp37-cp37m-manylinux2014_x86_64.whl (59.1 MB)\n","\u001b[K     |████████████████████████████████| 59.1 MB 104.1 MB/s \n","\u001b[?25hCollecting opendatasets\n","  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n","Collecting iterative-stratification\n","  Downloading iterative_stratification-0.1.7-py3-none-any.whl (8.5 kB)\n","Collecting wandb\n","  Downloading wandb-0.13.5-py2.py3-none-any.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 83.7 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 89.3 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 64.9 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Collecting xxhash\n","  Downloading xxhash-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 97.6 MB/s \n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.11.0)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.6)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n","\u001b[K     |████████████████████████████████| 115 kB 104.6 MB/s \n","\u001b[?25hRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 91.7 MB/s \n","\u001b[?25hCollecting alembic>=1.5.0\n","  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\n","\u001b[K     |████████████████████████████████| 209 kB 91.3 MB/s \n","\u001b[?25hCollecting cliff\n","  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n","\u001b[K     |████████████████████████████████| 81 kB 13.5 MB/s \n","\u001b[?25hRequirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.44)\n","Requirement already satisfied: scipy<1.9.0,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.3)\n","Collecting cmaes>=0.8.2\n","  Downloading cmaes-0.9.0-py3-none-any.whl (23 kB)\n","Collecting colorlog\n","  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n","Collecting Mako\n","  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n","\u001b[K     |████████████████████████████████| 78 kB 8.6 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (5.10.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray) (4.3.3)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.0.4)\n","Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray) (3.19.6)\n","Collecting virtualenv>=20.0.24\n","  Downloading virtualenv-20.16.7-py3-none-any.whl (8.8 MB)\n","\u001b[K     |████████████████████████████████| 8.8 MB 59.2 MB/s \n","\u001b[?25hRequirement already satisfied: click<=8.0.4,>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray) (7.1.2)\n","Requirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.50.0)\n","Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.32.0->ray) (1.15.0)\n","Collecting distlib<1,>=0.3.6\n","  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n","\u001b[K     |████████████████████████████████| 468 kB 89.2 MB/s \n","\u001b[?25hCollecting platformdirs<3,>=2.4\n","  Downloading platformdirs-2.5.4-py3-none-any.whl (14 kB)\n","Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from opendatasets) (1.5.12)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from iterative-stratification) (1.0.2)\n","Collecting setproctitle\n","  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.11.1-py2.py3-none-any.whl (168 kB)\n","\u001b[K     |████████████████████████████████| 168 kB 87.9 MB/s \n","\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 79.3 MB/s \n","\u001b[?25hCollecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 1.8 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.11.0-py2.py3-none-any.whl (168 kB)\n","\u001b[K     |████████████████████████████████| 168 kB 71.1 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.10.1-py2.py3-none-any.whl (166 kB)\n","\u001b[K     |████████████████████████████████| 166 kB 98.9 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.10.0-py2.py3-none-any.whl (166 kB)\n","\u001b[K     |████████████████████████████████| 166 kB 106.5 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.10-py2.py3-none-any.whl (162 kB)\n","\u001b[K     |████████████████████████████████| 162 kB 50.4 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.9-py2.py3-none-any.whl (162 kB)\n","\u001b[K     |████████████████████████████████| 162 kB 92.6 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n","\u001b[K     |████████████████████████████████| 158 kB 101.6 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.7-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 107.3 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.6-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 105.0 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 77.6 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 76.6 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 79.2 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 87.2 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 99.1 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n","\u001b[K     |████████████████████████████████| 156 kB 83.4 MB/s \n","\u001b[?25hCollecting stevedore>=2.0.1\n","  Downloading stevedore-3.5.2-py3-none-any.whl (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 8.0 MB/s \n","\u001b[?25hCollecting cmd2>=1.0.0\n","  Downloading cmd2-2.4.2-py3-none-any.whl (147 kB)\n","\u001b[K     |████████████████████████████████| 147 kB 88.8 MB/s \n","\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n","  Downloading pbr-5.11.0-py2.py3-none-any.whl (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 41.2 MB/s \n","\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.0)\n","Collecting autopage>=0.4.0\n","  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n","Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n","Collecting pyperclip>=1.6\n","  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (0.19.2)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.8.2)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (6.1.2)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.6)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->iterative-stratification) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->iterative-stratification) (3.1.0)\n","Building wheels for collected packages: pyperclip, pathtools\n","  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=bb4f988cf3b2fc05cccd49b59cae50827d19d5909316a3bab3bb35cd2a9cd6e9\n","  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=22a48a00a58c0cdd23bb3239ff0538994e1d3ddc038b65d2eccfcc2072ffda69\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built pyperclip pathtools\n","Installing collected packages: urllib3, smmap, pyperclip, pbr, stevedore, platformdirs, Mako, gitdb, distlib, cmd2, autopage, xxhash, virtualenv, tokenizers, shortuuid, setproctitle, sentry-sdk, responses, pathtools, multiprocess, huggingface-hub, GitPython, docker-pycreds, colorlog, cmaes, cliff, alembic, wandb, transformers, sentencepiece, ray, optuna, opendatasets, iterative-stratification, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed GitPython-3.1.29 Mako-1.2.4 alembic-1.8.1 autopage-0.5.1 cliff-3.10.1 cmaes-0.9.0 cmd2-2.4.2 colorlog-6.7.0 datasets-2.7.1 distlib-0.3.6 docker-pycreds-0.4.0 gitdb-4.0.10 huggingface-hub-0.11.0 iterative-stratification-0.1.7 multiprocess-0.70.14 opendatasets-0.1.22 optuna-3.0.3 pathtools-0.1.2 pbr-5.11.0 platformdirs-2.5.4 pyperclip-1.8.2 ray-2.1.0 responses-0.18.0 sentencepiece-0.1.97 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.11 smmap-5.0.0 stevedore-3.5.2 tokenizers-0.13.2 transformers-4.24.0 urllib3-1.25.11 virtualenv-20.16.7 wandb-0.13.5 xxhash-3.1.0\n","Sun Nov 27 14:52:54 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   43C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!pip install transformers datasets sentencepiece optuna ray opendatasets iterative-stratification wandb\n","!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5116,"status":"ok","timestamp":1669560780447,"user":{"displayName":"Feng Qilong","userId":"09603490936825460639"},"user_tz":-480},"id":"o-U0ryC8ibyB","outputId":"6510eba3-550e-42c1-d1a8-6b23e04ec14c"},"outputs":[{"output_type":"stream","name":"stdout","text":["tokenizers.__version__: 0.13.2\n","transformers.__version__: 4.24.0\n","env: TOKENIZERS_PARALLELISM=false\n"]}],"source":["import os\n","import gc\n","import re\n","import ast\n","import sys\n","import copy\n","import json\n","import time\n","import math\n","import string\n","import pickle\n","import random\n","import joblib\n","import itertools\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","from tqdm.auto import tqdm\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import Parameter\n","import torch.nn.functional as F\n","from torch.optim import Adam, SGD, AdamW\n","from torch.utils.data import DataLoader, Dataset\n","\n","import tokenizers\n","import transformers\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","from transformers import DataCollatorWithPadding\n","%env TOKENIZERS_PARALLELISM=false\n","os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{"id":"5eZCe2qHibyF"},"source":["# CFG"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20894,"status":"ok","timestamp":1669560801337,"user":{"displayName":"Feng Qilong","userId":"09603490936825460639"},"user_tz":-480},"id":"IjG7iLgajxPU","outputId":"5ec3279e-d6bd-4f6f-bb49-b6cdd0d8d825"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["target_cols = ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n","#/content/drive/MyDrive/Kaggle Training Results/English Language Learning/trained/robertabasemeanpooling/oof_df.pkl\n","#/content/drive/MyDrive/Kaggle Training Results/English Language Learning/trained/robertabaseattentionpooling/oof_df.pkl\n","\n","def MCRMSE(y_trues, y_preds):\n","    scores = []\n","    idxes = y_trues.shape[1]\n","    for i in range(idxes):\n","        y_true = y_trues[:,i]\n","        y_pred = y_preds[:,i]\n","        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n","        scores.append(score)\n","    mcrmse_score = np.mean(scores)\n","    return mcrmse_score, scores\n","\n","def get_score(y_trues, y_preds):\n","    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n","    return mcrmse_score, scores\n","\n","oof_df = pd.read_pickle(\"/content/drive/MyDrive/Kaggle Training Results/English Language Learning/trained/robertabaseattentionpooling/oof_df.pkl\")\n","cv = get_score(oof_df[target_cols].values, oof_df[[f\"pred_{c}\" for c in target_cols]].values)\n","print(cv)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dTcFNnlFk28P","executionInfo":{"status":"ok","timestamp":1669561159681,"user_tz":-480,"elapsed":1235,"user":{"displayName":"Feng Qilong","userId":"09603490936825460639"}},"outputId":"dbe6aed8-ebfc-44fb-8d8c-c0e4980db52b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(0.45207626539736295, [0.48569662419065474, 0.44481766183957777, 0.412822196189108, 0.4525196407436513, 0.4766498200374196, 0.4399516493837667])\n"]}]},{"cell_type":"code","source":["base = \"/content/drive/MyDrive/Kaggle Training Results/English Language Learning/trained/\""],"metadata":{"id":"RHtxvwsxhi2A"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sj6zplbkibyG"},"outputs":[],"source":["class CFG1:\n","    num_workers=4\n","    path=base + \"debertabasev3meanpooling/\"\n","    config_path=path + \"config.pth\"\n","    model=\"microsoft/deberta-v3-base\"\n","    tokenizer = AutoTokenizer.from_pretrained(path + \"tokenizer\")\n","    gradient_checkpointing=False\n","    batch_size = 48#4\n","    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n","    seed=42\n","    n_fold=4\n","    trn_fold=list(range(n_fold))\n","    init_weight=\"normal\" # xavier_uniform, xavier_normal, kaiming_uniform, kaiming_normal, orthogonal, normal\n","    pooling=\"mean\" # mean, attention, cls, concat\n","    msd_num=8\n","    msd=False\n","    \n","class CFG2:\n","    num_workers=4\n","    path=base + \"debertabasev3attentionpooling/\"\n","    config_path=path + \"config.pth\"\n","    model=\"microsoft/deberta-v3-base\"\n","    tokenizer = AutoTokenizer.from_pretrained(path + \"tokenizer\")\n","    gradient_checkpointing=False\n","    batch_size = 48#4\n","    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n","    seed=42\n","    n_fold=4\n","    trn_fold=list(range(n_fold))\n","    init_weight=\"normal\" # xavier_uniform, xavier_normal, kaiming_uniform, kaiming_normal, orthogonal, normal\n","    pooling=\"attention\" # mean, attention, cls, concat\n","    msd_num=8\n","    msd=False\n","    \n","class CFG3:\n","    num_workers=4\n","    path=base + \"debertabasev3clspooling/\"\n","    config_path=path + \"config.pth\"\n","    model=\"microsoft/deberta-v3-base\"\n","    tokenizer = AutoTokenizer.from_pretrained(path + \"tokenizer\")\n","    gradient_checkpointing=False\n","    batch_size = 48#4\n","    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n","    seed=42\n","    n_fold=4\n","    trn_fold=list(range(n_fold))\n","    init_weight=\"normal\" # xavier_uniform, xavier_normal, kaiming_uniform, kaiming_normal, orthogonal, normal\n","    pooling=\"cls\" # mean, attention, cls, concat\n","    msd_num=8\n","    msd=False\n","            \n","class CFG4:\n","    num_workers=4\n","    path=base + \"debertabasev3attentionpoolingfgm/\"\n","    config_path=path + 'config/config.json'\n","    model=\"microsoft/deberta-v3-base\"\n","    tokenizer = AutoTokenizer.from_pretrained(path + 'tokenizer')\n","    gradient_checkpointing=False\n","    batch_size = 48#4\n","    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n","    seed=42\n","    n_fold=4\n","    trn_fold=list(range(n_fold))\n","    pooling = 'attention'\n","    layer_start = 4\n","    \n","class CFG5:\n","    num_workers=4\n","    path=base + \"debertabasev3meanpoolingfgm/\"\n","    config_path=path + 'config/config.json'\n","    model=\"microsoft/deberta-v3-base\"\n","    tokenizer = AutoTokenizer.from_pretrained(path + 'tokenizer')\n","    gradient_checkpointing=False\n","    batch_size = 16#4\n","    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n","    seed=42\n","    n_fold=4\n","    trn_fold=list(range(n_fold))\n","    pooling = 'mean'\n","    layer_start = 4\n","    \n","class CFG6:\n","    num_workers=4\n","    path=base + \"debertalargev3meanpooling/\"\n","    config_path=path + \"config.pth\"\n","    model=\"microsoft/deberta-v3-large\"\n","    tokenizer = AutoTokenizer.from_pretrained(path + \"tokenizer\")\n","    gradient_checkpointing=False\n","    batch_size = 32#4\n","    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n","    seed=42\n","    n_fold=4\n","    trn_fold=list(range(n_fold))\n","    init_weight=\"normal\" # xavier_uniform, xavier_normal, kaiming_uniform, kaiming_normal, orthogonal, normal\n","    pooling=\"mean\" # mean, attention, cls, concat\n","    msd_num=8\n","    msd=False\n","    \n","class CFG7:\n","    num_workers=4\n","    path=base + \"debertalargev3attentionpooling/\"\n","    config_path=path + \"config.pth\"\n","    model=\"microsoft/deberta-v3-large\"\n","    tokenizer = AutoTokenizer.from_pretrained(path + \"tokenizer\")\n","    gradient_checkpointing=False\n","    batch_size = 32#4\n","    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n","    seed=42\n","    n_fold=4\n","    trn_fold=list(range(n_fold))\n","    init_weight=\"normal\" # xavier_uniform, xavier_normal, kaiming_uniform, kaiming_normal, orthogonal, normal\n","    pooling=\"attention\" # mean, attention, cls, concat\n","    msd_num=8\n","    msd=False\n","    \n","class CFG8:\n","    num_workers=4\n","    path=base + \"debertalargev3clspooling/\"\n","    config_path=path + \"config.pth\"\n","    model=\"microsoft/deberta-v3-large\"\n","    tokenizer = AutoTokenizer.from_pretrained(path + \"tokenizer\")\n","    gradient_checkpointing=False\n","    batch_size = 32#4\n","    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n","    seed=42\n","    n_fold=4\n","    trn_fold=list(range(n_fold))\n","    init_weight=\"normal\" # xavier_uniform, xavier_normal, kaiming_uniform, kaiming_normal, orthogonal, normal\n","    pooling=\"cls\" # mean, attention, cls, concat\n","    msd_num=8\n","    msd=False\n","\n","CFG_list1 = [CFG1, CFG2, CFG3, CFG6, CFG7, CFG8]\n","CFG_list2 = [CFG5, CFG4]\n","CFG_list = CFG_list1 + CFG_list2"]},{"cell_type":"markdown","metadata":{"id":"4--bowhZibyI"},"source":["# Utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B_2e4tDpibyI"},"outputs":[],"source":["# ====================================================\n","# Utils\n","# ====================================================\n","def MCRMSE(y_trues, y_preds):\n","    scores = []\n","    idxes = y_trues.shape[1]\n","    for i in range(idxes):\n","        y_true = y_trues[:,i]\n","        y_pred = y_preds[:,i]\n","        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n","        scores.append(score)\n","    mcrmse_score = np.mean(scores)\n","    return mcrmse_score, scores\n","\n","def get_score(y_trues, y_preds):\n","    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n","    return mcrmse_score, scores\n","\n","def get_logger(filename='inference'):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def get_oof(CFG):\n","    oof = pd.read_pickle(CFG.path+'oof_df.pkl')\n","    train = pd.read_csv('/content/drive/MyDrive/Kaggle Training Results/English Language Learning/data/train.csv').drop(columns=CFG1.target_cols + [\"full_text\"])\n","    merged = pd.merge(train, oof, how=\"left\", on=\"text_id\")\n","    return merged\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=42)"]},{"cell_type":"markdown","metadata":{"id":"CA_1BSHMibyJ"},"source":["# OOF"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4973,"status":"ok","timestamp":1669510775495,"user":{"displayName":"Feng Qilong","userId":"09603490936825460639"},"user_tz":-480},"id":"zX75JnfEibyJ","outputId":"d766d23a-2d73-4571-9ae6-b32371ce3ac0"},"outputs":[{"output_type":"stream","name":"stdout","text":["cv score: 0.44169211414706844\n"]}],"source":["# ====================================================\n","# oof\n","# ====================================================\n","oof_preds = []\n","labels = []\n","weights = np.load(\"/content/drive/MyDrive/Kaggle Training Results/English Language Learning/trained/ensemble_weights.npy\")\n","\n","for CFG in CFG_list:\n","    oof = get_oof(CFG)\n","    target = [\"pred_cohesion\", \"pred_syntax\", \"pred_vocabulary\", \"pred_phraseology\", \"pred_grammar\", \"pred_conventions\"]\n","    oof_preds.append(oof[target].values)\n","    labels = oof[CFG.target_cols].values\n","    \n","ensemble_preds = np.clip(np.average(oof_preds, weights=weights, axis=0), 1, 5)\n","score = get_score(labels, ensemble_preds)[0]\n","print(f\"cv score: {score}\")"]},{"cell_type":"markdown","metadata":{"id":"s4OqxNQ-ibyM"},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4VKRyryTibyM"},"outputs":[],"source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text):\n","    inputs = cfg.tokenizer.encode_plus(\n","        text, \n","        return_tensors=None, \n","        add_special_tokens=True, \n","        #max_length=CFG.max_len,\n","        #pad_to_max_length=True,\n","        #truncation=True\n","    )\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TestDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.texts = df['full_text'].values\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.texts[item])\n","        return inputs"]},{"cell_type":"markdown","metadata":{"id":"hubRq3KWibyM"},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aaohrrzAibyN"},"outputs":[],"source":["# ====================================================\n","# Model\n","# ====================================================\n","class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min = 1e-9)\n","        mean_embeddings = sum_embeddings/sum_mask\n","        return mean_embeddings\n","\n","class MaxPooling(nn.Module):\n","    def __init__(self):\n","        super(MaxPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        embeddings = last_hidden_state.clone()\n","        embeddings[input_mask_expanded == 0] = -1e4\n","        max_embeddings, _ = torch.max(embeddings, dim = 1)\n","        return max_embeddings\n","    \n","class MinPooling(nn.Module):\n","    def __init__(self):\n","        super(MinPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        embeddings = last_hidden_state.clone()\n","        embeddings[input_mask_expanded == 0] = 1e-4\n","        min_embeddings, _ = torch.min(embeddings, dim = 1)\n","        return min_embeddings\n","\n","#Attention pooling\n","class AttentionPooling(nn.Module):\n","    def __init__(self, in_dim):\n","        super().__init__()\n","        self.attention = nn.Sequential(\n","        nn.Linear(in_dim, in_dim),\n","        nn.LayerNorm(in_dim),\n","        nn.GELU(),\n","        nn.Linear(in_dim, 1),\n","        )\n","\n","    def forward(self, last_hidden_state, attention_mask):\n","        w = self.attention(last_hidden_state).float()\n","        w[attention_mask==0]=float('-inf')\n","        w = torch.softmax(w,1)\n","        attention_embeddings = torch.sum(w * last_hidden_state, dim=1)\n","        return attention_embeddings\n","\n","#There may be a bug in my implementation because it does not work well.\n","class WeightedLayerPooling(nn.Module):\n","    def __init__(self, num_hidden_layers, layer_start: int = 4, layer_weights = None):\n","        super(WeightedLayerPooling, self).__init__()\n","        self.layer_start = layer_start\n","        self.num_hidden_layers = num_hidden_layers\n","        self.layer_weights = layer_weights if layer_weights is not None \\\n","            else nn.Parameter(\n","                torch.tensor([1] * (num_hidden_layers+1 - layer_start), dtype=torch.float)\n","            )\n","\n","    def forward(self, ft_all_layers):\n","        all_layer_embedding = torch.stack(ft_all_layers)\n","        all_layer_embedding = all_layer_embedding[self.layer_start:, :, :, :]\n","\n","        weight_factor = self.layer_weights.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).expand(all_layer_embedding.size())\n","        weighted_average = (weight_factor*all_layer_embedding).sum(dim=0) / self.layer_weights.sum()\n","\n","        return weighted_average"]},{"cell_type":"markdown","metadata":{"id":"mqZ8MeuXibyN"},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mD6MPcBhibyN"},"outputs":[],"source":["class Model1(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","            self.config.hidden_dropout = 0.\n","            self.config.hidden_dropout_prob = 0.\n","            self.config.attention_dropout = 0.\n","            self.config.attention_probs_dropout_prob = 0.\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel.from_config(self.config)\n","        if self.cfg.gradient_checkpointing:\n","            self.model.gradient_checkpointing_enable()\n","        \n","        self.pool = MeanPooling()\n","        self.attention = AttentionPooling(self.config.hidden_size)\n","        self.dropout = nn.Dropout(p=0.2)\n","        self.high_dropout = nn.Dropout(p=0.5)\n","        self.concat_pool = nn.Linear(self.config.hidden_size*3, self.config.hidden_size)\n","        self.fc = nn.Linear(self.config.hidden_size, 6)\n","        self._init_weights(self.fc)\n","        self._init_weights(self.concat_pool)\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            if CFG.init_weight == 'normal':\n","                module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            elif CFG.init_weight == 'xavier_uniform':\n","                module.weight.data = nn.init.xavier_uniform_(module.weight.data)\n","            elif CFG.init_weight == 'xavier_normal':\n","                module.weight.data = nn.init.xavier_normal_(module.weight.data)\n","            elif CFG.init_weight == 'kaiming_uniform':\n","                module.weight.data = nn.init.kaiming_uniform_(module.weight.data)\n","            elif CFG.init_weight == 'kaiming_normal':\n","                module.weight.data = nn.init.kaiming_normal_(module.weight.data)\n","            elif CFG.init_weight == 'orthogonal':\n","                module.weight.data = nn.init.orthogonal_(module.weight.data) \n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            if CFG.init_weight == 'normal':\n","                module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            elif CFG.init_weight == 'xavier_uniform':\n","                module.weight.data = nn.init.xavier_uniform_(module.weight.data)\n","            elif CFG.init_weight == 'xavier_normal':\n","                module.weight.data = nn.init.xavier_normal_(module.weight.data)\n","            elif CFG.init_weight == 'kaiming_uniform':\n","                module.weight.data = nn.init.kaiming_uniform_(module.weight.data)\n","            elif CFG.init_weight == 'kaiming_normal':\n","                module.weight.data = nn.init.kaiming_normal_(module.weight.data)\n","            elif CFG.init_weight == 'orthogonal':\n","                module.weight.data = nn.init.orthogonal_(module.weight.data) \n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs.last_hidden_state\n","\n","        if self.cfg.msd:\n","            mean_feature = torch.mean(torch.stack([self.pool(self.high_dropout(last_hidden_states), inputs['attention_mask']) for _ in range(self.cfg.msd_num)], dim=0), dim=0)    \n","            attention_feature = torch.mean(torch.stack([self.pool(self.high_dropout(last_hidden_states), inputs['attention_mask']) for _ in range(self.cfg.msd_num)], dim=0), dim=0)  \n","            cls_token_feature = torch.mean(torch.stack([self.high_dropout(last_hidden_states)[:, 0, :] for _ in range(self.cfg.msd_num)], dim=0), dim=0)\n","            combine_feature = torch.cat([mean_feature, attention_feature, cls_token_feature], dim = -1)\n","            feature = self.concat_pool(combine_feature)\n","            if self.cfg.pooling == \"mean\":\n","                return mean_feature\n","            elif self.cfg.pooling == \"attention\":\n","                return attention_feature\n","            elif self.cfg.pooling == \"cls\":\n","                return cls_token_feature\n","            else:\n","                return feature\n","        else:\n","        # mean pooled sentence representation\n","            mean_feature = self.pool(last_hidden_states, inputs['attention_mask'])\n","        # attention based sentence representation\n","            attention_feature = self.attention(last_hidden_states, inputs['attention_mask'])\n","        # CLS Token representation\n","            cls_token_feature = last_hidden_states[:, 0, :] # only cls token\n","        # Concat them\n","            combine_feature = torch.cat([mean_feature, attention_feature, cls_token_feature], dim = -1)\n","        # MLP\n","            feature = self.concat_pool(combine_feature)\n","            if self.cfg.pooling == \"mean\":\n","                return mean_feature\n","            elif self.cfg.pooling == \"attention\":\n","                return attention_feature\n","            elif self.cfg.pooling == \"cls\":\n","                return cls_token_feature\n","            else:\n","                return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        output = self.fc(feature)\n","        return output\n","    \n","class Model2(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","            self.config.hidden_dropout = 0.\n","            self.config.hidden_dropout_prob = 0.\n","            self.config.attention_dropout = 0.\n","            self.config.attention_probs_dropout_prob = 0.\n","            LOGGER.info(self.config)\n","        else:\n","            #self.config = torch.load(config_path)\n","            self.config = AutoConfig.from_pretrained(config_path, output_hidden_states=True)\n","            LOGGER.info(self.config)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel.from_config(self.config)\n","        if self.cfg.gradient_checkpointing:\n","            self.model.gradient_checkpointing_enable()\n","        \n","        if CFG.pooling == 'mean':\n","            self.pool = MeanPooling()\n","        elif CFG.pooling == 'max':\n","            self.pool = MaxPooling()\n","        elif CFG.pooling == 'min':\n","            self.pool = MinPooling()\n","        elif CFG.pooling == 'attention':\n","            self.pool = AttentionPooling(self.config.hidden_size)\n","        elif CFG.pooling == 'weightedlayer':\n","            self.pool = WeightedLayerPooling(self.config.num_hidden_layers, layer_start = CFG.layer_start, layer_weights = None)        \n","\n","        self.fc = nn.Linear(self.config.hidden_size, 6)\n","        self._init_weights(self.fc)\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        output = self.fc(feature)\n","        return output"]},{"cell_type":"markdown","metadata":{"id":"hgudhdp2ibyO"},"source":["# inference"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xqTLZUVfibyO"},"outputs":[],"source":["# ====================================================\n","# inference\n","# ====================================================\n","def inference_fn(test_loader, model, device):\n","    preds = []\n","    model.eval()\n","    model.to(device)\n","    tk0 = tqdm(test_loader, total=len(test_loader))\n","    for inputs in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        preds.append(y_preds.to('cpu').numpy())\n","    predictions = np.concatenate(preds)\n","    return predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mdFvOmMJibyO"},"outputs":[],"source":["final = []\n","for _idx, CFG in enumerate(CFG_list):\n","    test = pd.read_csv('/content/drive/MyDrive/Kaggle Training Results/English Language Learning/data/prev_train.csv', index_col=0).drop_duplicates(subset=['text_id'])\n","    submission = pd.read_csv(\"/content/drive/MyDrive/Kaggle Training Results/English Language Learning/data/prev_train.csv\", index_col=0).drop_duplicates(subset=['text_id'])\n","    # sort by length to speed up inference\n","    test['tokenize_length'] = [len(CFG.tokenizer(text)['input_ids']) for text in test['full_text'].values]\n","    test = test.sort_values('tokenize_length', ascending=True).reset_index(drop=True)\n","\n","    test_dataset = TestDataset(CFG, test)\n","    test_loader = DataLoader(test_dataset,\n","                             batch_size=CFG.batch_size,\n","                             shuffle=False,\n","                             collate_fn=DataCollatorWithPadding(tokenizer=CFG.tokenizer, padding='longest'),\n","                             num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","    predictions = []\n","    for fold in CFG.trn_fold:\n","        if _idx < 6:\n","            model = Model1(CFG, config_path=CFG.config_path, pretrained=False)\n","            state = torch.load(CFG.path+f\"modelfold{fold + 1}normalllrdnomsdnormal.pth\",\n","                           map_location=torch.device('cpu'))\n","            model.load_state_dict(state)\n","        else:\n","            model = Model2(CFG, config_path=CFG.config_path, pretrained=False)\n","            state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                           map_location=torch.device('cpu'))\n","            model.load_state_dict(state['model'])\n","        prediction = inference_fn(test_loader, model, device)\n","        predictions.append(prediction)\n","        del model, state, prediction; gc.collect()\n","        torch.cuda.empty_cache()\n","    predictions = np.mean(predictions, axis=0)\n","    test[CFG.target_cols] = predictions\n","    submission = pd.merge(submission[\"text_id\"], test[[\"text_id\"] + CFG.target_cols], how=\"left\")\n","    final.append(submission[CFG.target_cols].values)\n","    del test, submission, predictions, test_dataset, test_loader; gc.collect()\n","    torch.cuda.empty_cache() "]},{"cell_type":"markdown","metadata":{"id":"ruJtsKyDibyO"},"source":["# Ensemble"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":441},"id":"MHOOUKTEibyO","outputId":"672e860c-c0db-4692-8698-69d79ab51375","collapsed":true,"executionInfo":{"status":"ok","timestamp":1669522816333,"user_tz":-480,"elapsed":2990,"user":{"displayName":"Feng Qilong","userId":"09603490936825460639"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["15142\n"]},{"output_type":"display_data","data":{"text/plain":["            text_id                                          full_text  \\\n","0      423A1CA112E2  Phones\\n\\nModern humans today are always on th...   \n","1      A8445CABFECE  Phones & Driving\\n\\nDrivers should not be able...   \n","2      6B4F7A0165B9  Cell Phone Operation While Driving\\n\\nThe abil...   \n","3      E05C7F5C1156  People are debating whether if drivers should ...   \n","4      50B3435E475B  Texting and driving\\n\\nOver half of drivers in...   \n","...             ...                                                ...   \n","15137  0814426B27DF  Most people ask more than one person for advic...   \n","15138  8F4B595CF9E7  Do you ever want more opinions and options whe...   \n","15139  6B5809C83978  Has anyone ever gave you advice? Was the advic...   \n","15140  AFEC37C2D43F  There has been at least one point in everyone'...   \n","15141  4C471936CD75  In ancient times, and also still today in some...   \n","\n","       cohesion    syntax  vocabulary  phraseology   grammar  conventions  \n","0      3.056048  3.112964    3.345940     3.206383  3.084330     3.322059  \n","1      3.710860  3.760511    3.786949     3.763001  3.782464     3.918429  \n","2      4.053563  4.069672    4.481086     4.328255  4.303818     4.165030  \n","3      4.110247  4.031701    4.162265     4.095508  3.993166     4.082003  \n","4      3.845428  3.925613    4.090289     4.076712  4.128270     3.972077  \n","...         ...       ...         ...          ...       ...          ...  \n","15137  3.305353  3.320829    3.459901     3.451811  3.593226     3.524821  \n","15138  3.959244  3.955805    4.054248     4.072804  4.118625     4.013373  \n","15139  4.187916  4.175071    4.120436     4.159891  4.297247     4.299526  \n","15140  4.045924  4.010312    4.133028     4.121380  4.199779     3.930347  \n","15141  4.266560  4.200973    4.347042     4.269538  4.350202     4.234642  \n","\n","[15142 rows x 8 columns]"],"text/html":["\n","  <div id=\"df-d56f8d60-5f12-4057-ae47-93a73dbb9dff\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>full_text</th>\n","      <th>cohesion</th>\n","      <th>syntax</th>\n","      <th>vocabulary</th>\n","      <th>phraseology</th>\n","      <th>grammar</th>\n","      <th>conventions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>423A1CA112E2</td>\n","      <td>Phones\\n\\nModern humans today are always on th...</td>\n","      <td>3.056048</td>\n","      <td>3.112964</td>\n","      <td>3.345940</td>\n","      <td>3.206383</td>\n","      <td>3.084330</td>\n","      <td>3.322059</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A8445CABFECE</td>\n","      <td>Phones &amp; Driving\\n\\nDrivers should not be able...</td>\n","      <td>3.710860</td>\n","      <td>3.760511</td>\n","      <td>3.786949</td>\n","      <td>3.763001</td>\n","      <td>3.782464</td>\n","      <td>3.918429</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>6B4F7A0165B9</td>\n","      <td>Cell Phone Operation While Driving\\n\\nThe abil...</td>\n","      <td>4.053563</td>\n","      <td>4.069672</td>\n","      <td>4.481086</td>\n","      <td>4.328255</td>\n","      <td>4.303818</td>\n","      <td>4.165030</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>E05C7F5C1156</td>\n","      <td>People are debating whether if drivers should ...</td>\n","      <td>4.110247</td>\n","      <td>4.031701</td>\n","      <td>4.162265</td>\n","      <td>4.095508</td>\n","      <td>3.993166</td>\n","      <td>4.082003</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>50B3435E475B</td>\n","      <td>Texting and driving\\n\\nOver half of drivers in...</td>\n","      <td>3.845428</td>\n","      <td>3.925613</td>\n","      <td>4.090289</td>\n","      <td>4.076712</td>\n","      <td>4.128270</td>\n","      <td>3.972077</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>15137</th>\n","      <td>0814426B27DF</td>\n","      <td>Most people ask more than one person for advic...</td>\n","      <td>3.305353</td>\n","      <td>3.320829</td>\n","      <td>3.459901</td>\n","      <td>3.451811</td>\n","      <td>3.593226</td>\n","      <td>3.524821</td>\n","    </tr>\n","    <tr>\n","      <th>15138</th>\n","      <td>8F4B595CF9E7</td>\n","      <td>Do you ever want more opinions and options whe...</td>\n","      <td>3.959244</td>\n","      <td>3.955805</td>\n","      <td>4.054248</td>\n","      <td>4.072804</td>\n","      <td>4.118625</td>\n","      <td>4.013373</td>\n","    </tr>\n","    <tr>\n","      <th>15139</th>\n","      <td>6B5809C83978</td>\n","      <td>Has anyone ever gave you advice? Was the advic...</td>\n","      <td>4.187916</td>\n","      <td>4.175071</td>\n","      <td>4.120436</td>\n","      <td>4.159891</td>\n","      <td>4.297247</td>\n","      <td>4.299526</td>\n","    </tr>\n","    <tr>\n","      <th>15140</th>\n","      <td>AFEC37C2D43F</td>\n","      <td>There has been at least one point in everyone'...</td>\n","      <td>4.045924</td>\n","      <td>4.010312</td>\n","      <td>4.133028</td>\n","      <td>4.121380</td>\n","      <td>4.199779</td>\n","      <td>3.930347</td>\n","    </tr>\n","    <tr>\n","      <th>15141</th>\n","      <td>4C471936CD75</td>\n","      <td>In ancient times, and also still today in some...</td>\n","      <td>4.266560</td>\n","      <td>4.200973</td>\n","      <td>4.347042</td>\n","      <td>4.269538</td>\n","      <td>4.350202</td>\n","      <td>4.234642</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>15142 rows × 8 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d56f8d60-5f12-4057-ae47-93a73dbb9dff')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d56f8d60-5f12-4057-ae47-93a73dbb9dff button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d56f8d60-5f12-4057-ae47-93a73dbb9dff');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}],"source":["pseudo = pd.read_csv('/content/drive/MyDrive/Kaggle Training Results/English Language Learning/data/prev_train.csv', index_col=0).drop_duplicates(subset=['text_id'])\n","\n","ens = np.clip(np.average(final, weights=weights, axis=0), 1, 5)\n","np.save(\"/content/drive/MyDrive/Kaggle Training Results/English Language Learning/trained/ens.npy\", ens)\n","print(len(ens))\n","\n","#ens = (sub1 + sub2)/(CFG1.weight + CFG2.weight)\n","\n","pseudo[CFG1.target_cols] = ens\n","display(pseudo)\n","pseudo.to_csv(f'/content/drive/MyDrive/Kaggle Training Results/English Language Learning/trained/pseudo.csv', index=False)"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":0}