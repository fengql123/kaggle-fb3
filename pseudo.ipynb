{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5116,"status":"ok","timestamp":1669560780447,"user":{"displayName":"Feng Qilong","userId":"09603490936825460639"},"user_tz":-480},"id":"o-U0ryC8ibyB","outputId":"6510eba3-550e-42c1-d1a8-6b23e04ec14c"},"outputs":[{"name":"stdout","output_type":"stream","text":["tokenizers.__version__: 0.13.2\n","transformers.__version__: 4.24.0\n","env: TOKENIZERS_PARALLELISM=false\n"]}],"source":["import os\n","import gc\n","import re\n","import ast\n","import sys\n","import copy\n","import json\n","import time\n","import math\n","import string\n","import pickle\n","import random\n","import joblib\n","import itertools\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","from tqdm.auto import tqdm\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import Parameter\n","import torch.nn.functional as F\n","from torch.optim import Adam, SGD, AdamW\n","from torch.utils.data import DataLoader, Dataset\n","\n","import tokenizers\n","import transformers\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","from transformers import DataCollatorWithPadding\n","%env TOKENIZERS_PARALLELISM=false\n","os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{"id":"5eZCe2qHibyF"},"source":["# CFG"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1235,"status":"ok","timestamp":1669561159681,"user":{"displayName":"Feng Qilong","userId":"09603490936825460639"},"user_tz":-480},"id":"dTcFNnlFk28P","outputId":"dbe6aed8-ebfc-44fb-8d8c-c0e4980db52b"},"outputs":[{"name":"stdout","output_type":"stream","text":["(0.45207626539736295, [0.48569662419065474, 0.44481766183957777, 0.412822196189108, 0.4525196407436513, 0.4766498200374196, 0.4399516493837667])\n"]}],"source":["target_cols = ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n","#/content/drive/MyDrive/Kaggle Training Results/English Language Learning/trained/robertabasemeanpooling/oof_df.pkl\n","#/content/drive/MyDrive/Kaggle Training Results/English Language Learning/trained/robertabaseattentionpooling/oof_df.pkl\n","\n","def MCRMSE(y_trues, y_preds):\n","    scores = []\n","    idxes = y_trues.shape[1]\n","    for i in range(idxes):\n","        y_true = y_trues[:,i]\n","        y_pred = y_preds[:,i]\n","        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n","        scores.append(score)\n","    mcrmse_score = np.mean(scores)\n","    return mcrmse_score, scores\n","\n","def get_score(y_trues, y_preds):\n","    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n","    return mcrmse_score, scores\n","\n","oof_df = pd.read_pickle(\"/content/drive/MyDrive/Kaggle Training Results/English Language Learning/trained/robertabaseattentionpooling/oof_df.pkl\")\n","cv = get_score(oof_df[target_cols].values, oof_df[[f\"pred_{c}\" for c in target_cols]].values)\n","print(cv)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RHtxvwsxhi2A"},"outputs":[],"source":["base = \"/content/drive/MyDrive/Kaggle Training Results/English Language Learning/trained/\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sj6zplbkibyG"},"outputs":[],"source":["class CFG1:\n","    num_workers=4\n","    path=base + \"debertabasev3meanpooling/\"\n","    config_path=path + \"config.pth\"\n","    model=\"microsoft/deberta-v3-base\"\n","    tokenizer = AutoTokenizer.from_pretrained(path + \"tokenizer\")\n","    gradient_checkpointing=False\n","    batch_size = 48#4\n","    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n","    seed=42\n","    n_fold=4\n","    trn_fold=list(range(n_fold))\n","    init_weight=\"normal\" # xavier_uniform, xavier_normal, kaiming_uniform, kaiming_normal, orthogonal, normal\n","    pooling=\"mean\" # mean, attention, cls, concat\n","    msd_num=8\n","    msd=False\n","    \n","class CFG2:\n","    num_workers=4\n","    path=base + \"debertabasev3attentionpooling/\"\n","    config_path=path + \"config.pth\"\n","    model=\"microsoft/deberta-v3-base\"\n","    tokenizer = AutoTokenizer.from_pretrained(path + \"tokenizer\")\n","    gradient_checkpointing=False\n","    batch_size = 48#4\n","    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n","    seed=42\n","    n_fold=4\n","    trn_fold=list(range(n_fold))\n","    init_weight=\"normal\" # xavier_uniform, xavier_normal, kaiming_uniform, kaiming_normal, orthogonal, normal\n","    pooling=\"attention\" # mean, attention, cls, concat\n","    msd_num=8\n","    msd=False\n","    \n","class CFG3:\n","    num_workers=4\n","    path=base + \"debertabasev3clspooling/\"\n","    config_path=path + \"config.pth\"\n","    model=\"microsoft/deberta-v3-base\"\n","    tokenizer = AutoTokenizer.from_pretrained(path + \"tokenizer\")\n","    gradient_checkpointing=False\n","    batch_size = 48#4\n","    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n","    seed=42\n","    n_fold=4\n","    trn_fold=list(range(n_fold))\n","    init_weight=\"normal\" # xavier_uniform, xavier_normal, kaiming_uniform, kaiming_normal, orthogonal, normal\n","    pooling=\"cls\" # mean, attention, cls, concat\n","    msd_num=8\n","    msd=False\n","            \n","class CFG4:\n","    num_workers=4\n","    path=base + \"debertabasev3attentionpoolingfgm/\"\n","    config_path=path + 'config/config.json'\n","    model=\"microsoft/deberta-v3-base\"\n","    tokenizer = AutoTokenizer.from_pretrained(path + 'tokenizer')\n","    gradient_checkpointing=False\n","    batch_size = 48#4\n","    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n","    seed=42\n","    n_fold=4\n","    trn_fold=list(range(n_fold))\n","    pooling = 'attention'\n","    layer_start = 4\n","    \n","class CFG5:\n","    num_workers=4\n","    path=base + \"debertabasev3meanpoolingfgm/\"\n","    config_path=path + 'config/config.json'\n","    model=\"microsoft/deberta-v3-base\"\n","    tokenizer = AutoTokenizer.from_pretrained(path + 'tokenizer')\n","    gradient_checkpointing=False\n","    batch_size = 16#4\n","    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n","    seed=42\n","    n_fold=4\n","    trn_fold=list(range(n_fold))\n","    pooling = 'mean'\n","    layer_start = 4\n","    \n","class CFG6:\n","    num_workers=4\n","    path=base + \"debertalargev3meanpooling/\"\n","    config_path=path + \"config.pth\"\n","    model=\"microsoft/deberta-v3-large\"\n","    tokenizer = AutoTokenizer.from_pretrained(path + \"tokenizer\")\n","    gradient_checkpointing=False\n","    batch_size = 32#4\n","    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n","    seed=42\n","    n_fold=4\n","    trn_fold=list(range(n_fold))\n","    init_weight=\"normal\" # xavier_uniform, xavier_normal, kaiming_uniform, kaiming_normal, orthogonal, normal\n","    pooling=\"mean\" # mean, attention, cls, concat\n","    msd_num=8\n","    msd=False\n","    \n","class CFG7:\n","    num_workers=4\n","    path=base + \"debertalargev3attentionpooling/\"\n","    config_path=path + \"config.pth\"\n","    model=\"microsoft/deberta-v3-large\"\n","    tokenizer = AutoTokenizer.from_pretrained(path + \"tokenizer\")\n","    gradient_checkpointing=False\n","    batch_size = 32#4\n","    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n","    seed=42\n","    n_fold=4\n","    trn_fold=list(range(n_fold))\n","    init_weight=\"normal\" # xavier_uniform, xavier_normal, kaiming_uniform, kaiming_normal, orthogonal, normal\n","    pooling=\"attention\" # mean, attention, cls, concat\n","    msd_num=8\n","    msd=False\n","    \n","class CFG8:\n","    num_workers=4\n","    path=base + \"debertalargev3clspooling/\"\n","    config_path=path + \"config.pth\"\n","    model=\"microsoft/deberta-v3-large\"\n","    tokenizer = AutoTokenizer.from_pretrained(path + \"tokenizer\")\n","    gradient_checkpointing=False\n","    batch_size = 32#4\n","    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n","    seed=42\n","    n_fold=4\n","    trn_fold=list(range(n_fold))\n","    init_weight=\"normal\" # xavier_uniform, xavier_normal, kaiming_uniform, kaiming_normal, orthogonal, normal\n","    pooling=\"cls\" # mean, attention, cls, concat\n","    msd_num=8\n","    msd=False\n","\n","CFG_list1 = [CFG1, CFG2, CFG3, CFG6, CFG7, CFG8]\n","CFG_list2 = [CFG5, CFG4]\n","CFG_list = CFG_list1 + CFG_list2"]},{"cell_type":"markdown","metadata":{"id":"4--bowhZibyI"},"source":["# Utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B_2e4tDpibyI"},"outputs":[],"source":["# ====================================================\n","# Utils\n","# ====================================================\n","def MCRMSE(y_trues, y_preds):\n","    scores = []\n","    idxes = y_trues.shape[1]\n","    for i in range(idxes):\n","        y_true = y_trues[:,i]\n","        y_pred = y_preds[:,i]\n","        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n","        scores.append(score)\n","    mcrmse_score = np.mean(scores)\n","    return mcrmse_score, scores\n","\n","def get_score(y_trues, y_preds):\n","    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n","    return mcrmse_score, scores\n","\n","def get_logger(filename='inference'):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def get_oof(CFG):\n","    oof = pd.read_pickle(CFG.path+'oof_df.pkl')\n","    train = pd.read_csv('/content/drive/MyDrive/Kaggle Training Results/English Language Learning/data/train.csv').drop(columns=CFG1.target_cols + [\"full_text\"])\n","    merged = pd.merge(train, oof, how=\"left\", on=\"text_id\")\n","    return merged\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=42)"]},{"cell_type":"markdown","metadata":{"id":"CA_1BSHMibyJ"},"source":["# OOF"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4973,"status":"ok","timestamp":1669510775495,"user":{"displayName":"Feng Qilong","userId":"09603490936825460639"},"user_tz":-480},"id":"zX75JnfEibyJ","outputId":"d766d23a-2d73-4571-9ae6-b32371ce3ac0"},"outputs":[{"name":"stdout","output_type":"stream","text":["cv score: 0.44169211414706844\n"]}],"source":["# ====================================================\n","# oof\n","# ====================================================\n","oof_preds = []\n","labels = []\n","weights = np.load(\"/content/drive/MyDrive/Kaggle Training Results/English Language Learning/trained/ensemble_weights.npy\")\n","\n","for CFG in CFG_list:\n","    oof = get_oof(CFG)\n","    target = [\"pred_cohesion\", \"pred_syntax\", \"pred_vocabulary\", \"pred_phraseology\", \"pred_grammar\", \"pred_conventions\"]\n","    oof_preds.append(oof[target].values)\n","    labels = oof[CFG.target_cols].values\n","    \n","ensemble_preds = np.clip(np.average(oof_preds, weights=weights, axis=0), 1, 5)\n","score = get_score(labels, ensemble_preds)[0]\n","print(f\"cv score: {score}\")"]},{"cell_type":"markdown","metadata":{"id":"s4OqxNQ-ibyM"},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4VKRyryTibyM"},"outputs":[],"source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text):\n","    inputs = cfg.tokenizer.encode_plus(\n","        text, \n","        return_tensors=None, \n","        add_special_tokens=True, \n","        #max_length=CFG.max_len,\n","        #pad_to_max_length=True,\n","        #truncation=True\n","    )\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TestDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.texts = df['full_text'].values\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.texts[item])\n","        return inputs"]},{"cell_type":"markdown","metadata":{"id":"hubRq3KWibyM"},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aaohrrzAibyN"},"outputs":[],"source":["# ====================================================\n","# Model\n","# ====================================================\n","class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min = 1e-9)\n","        mean_embeddings = sum_embeddings/sum_mask\n","        return mean_embeddings\n","\n","class MaxPooling(nn.Module):\n","    def __init__(self):\n","        super(MaxPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        embeddings = last_hidden_state.clone()\n","        embeddings[input_mask_expanded == 0] = -1e4\n","        max_embeddings, _ = torch.max(embeddings, dim = 1)\n","        return max_embeddings\n","    \n","class MinPooling(nn.Module):\n","    def __init__(self):\n","        super(MinPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        embeddings = last_hidden_state.clone()\n","        embeddings[input_mask_expanded == 0] = 1e-4\n","        min_embeddings, _ = torch.min(embeddings, dim = 1)\n","        return min_embeddings\n","\n","#Attention pooling\n","class AttentionPooling(nn.Module):\n","    def __init__(self, in_dim):\n","        super().__init__()\n","        self.attention = nn.Sequential(\n","        nn.Linear(in_dim, in_dim),\n","        nn.LayerNorm(in_dim),\n","        nn.GELU(),\n","        nn.Linear(in_dim, 1),\n","        )\n","\n","    def forward(self, last_hidden_state, attention_mask):\n","        w = self.attention(last_hidden_state).float()\n","        w[attention_mask==0]=float('-inf')\n","        w = torch.softmax(w,1)\n","        attention_embeddings = torch.sum(w * last_hidden_state, dim=1)\n","        return attention_embeddings\n","\n","#There may be a bug in my implementation because it does not work well.\n","class WeightedLayerPooling(nn.Module):\n","    def __init__(self, num_hidden_layers, layer_start: int = 4, layer_weights = None):\n","        super(WeightedLayerPooling, self).__init__()\n","        self.layer_start = layer_start\n","        self.num_hidden_layers = num_hidden_layers\n","        self.layer_weights = layer_weights if layer_weights is not None \\\n","            else nn.Parameter(\n","                torch.tensor([1] * (num_hidden_layers+1 - layer_start), dtype=torch.float)\n","            )\n","\n","    def forward(self, ft_all_layers):\n","        all_layer_embedding = torch.stack(ft_all_layers)\n","        all_layer_embedding = all_layer_embedding[self.layer_start:, :, :, :]\n","\n","        weight_factor = self.layer_weights.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).expand(all_layer_embedding.size())\n","        weighted_average = (weight_factor*all_layer_embedding).sum(dim=0) / self.layer_weights.sum()\n","\n","        return weighted_average"]},{"cell_type":"markdown","metadata":{"id":"mqZ8MeuXibyN"},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mD6MPcBhibyN"},"outputs":[],"source":["class Model1(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","            self.config.hidden_dropout = 0.\n","            self.config.hidden_dropout_prob = 0.\n","            self.config.attention_dropout = 0.\n","            self.config.attention_probs_dropout_prob = 0.\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel.from_config(self.config)\n","        if self.cfg.gradient_checkpointing:\n","            self.model.gradient_checkpointing_enable()\n","        \n","        self.pool = MeanPooling()\n","        self.attention = AttentionPooling(self.config.hidden_size)\n","        self.dropout = nn.Dropout(p=0.2)\n","        self.high_dropout = nn.Dropout(p=0.5)\n","        self.concat_pool = nn.Linear(self.config.hidden_size*3, self.config.hidden_size)\n","        self.fc = nn.Linear(self.config.hidden_size, 6)\n","        self._init_weights(self.fc)\n","        self._init_weights(self.concat_pool)\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            if CFG.init_weight == 'normal':\n","                module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            elif CFG.init_weight == 'xavier_uniform':\n","                module.weight.data = nn.init.xavier_uniform_(module.weight.data)\n","            elif CFG.init_weight == 'xavier_normal':\n","                module.weight.data = nn.init.xavier_normal_(module.weight.data)\n","            elif CFG.init_weight == 'kaiming_uniform':\n","                module.weight.data = nn.init.kaiming_uniform_(module.weight.data)\n","            elif CFG.init_weight == 'kaiming_normal':\n","                module.weight.data = nn.init.kaiming_normal_(module.weight.data)\n","            elif CFG.init_weight == 'orthogonal':\n","                module.weight.data = nn.init.orthogonal_(module.weight.data) \n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            if CFG.init_weight == 'normal':\n","                module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            elif CFG.init_weight == 'xavier_uniform':\n","                module.weight.data = nn.init.xavier_uniform_(module.weight.data)\n","            elif CFG.init_weight == 'xavier_normal':\n","                module.weight.data = nn.init.xavier_normal_(module.weight.data)\n","            elif CFG.init_weight == 'kaiming_uniform':\n","                module.weight.data = nn.init.kaiming_uniform_(module.weight.data)\n","            elif CFG.init_weight == 'kaiming_normal':\n","                module.weight.data = nn.init.kaiming_normal_(module.weight.data)\n","            elif CFG.init_weight == 'orthogonal':\n","                module.weight.data = nn.init.orthogonal_(module.weight.data) \n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs.last_hidden_state\n","\n","        if self.cfg.msd:\n","            mean_feature = torch.mean(torch.stack([self.pool(self.high_dropout(last_hidden_states), inputs['attention_mask']) for _ in range(self.cfg.msd_num)], dim=0), dim=0)    \n","            attention_feature = torch.mean(torch.stack([self.pool(self.high_dropout(last_hidden_states), inputs['attention_mask']) for _ in range(self.cfg.msd_num)], dim=0), dim=0)  \n","            cls_token_feature = torch.mean(torch.stack([self.high_dropout(last_hidden_states)[:, 0, :] for _ in range(self.cfg.msd_num)], dim=0), dim=0)\n","            combine_feature = torch.cat([mean_feature, attention_feature, cls_token_feature], dim = -1)\n","            feature = self.concat_pool(combine_feature)\n","            if self.cfg.pooling == \"mean\":\n","                return mean_feature\n","            elif self.cfg.pooling == \"attention\":\n","                return attention_feature\n","            elif self.cfg.pooling == \"cls\":\n","                return cls_token_feature\n","            else:\n","                return feature\n","        else:\n","        # mean pooled sentence representation\n","            mean_feature = self.pool(last_hidden_states, inputs['attention_mask'])\n","        # attention based sentence representation\n","            attention_feature = self.attention(last_hidden_states, inputs['attention_mask'])\n","        # CLS Token representation\n","            cls_token_feature = last_hidden_states[:, 0, :] # only cls token\n","        # Concat them\n","            combine_feature = torch.cat([mean_feature, attention_feature, cls_token_feature], dim = -1)\n","        # MLP\n","            feature = self.concat_pool(combine_feature)\n","            if self.cfg.pooling == \"mean\":\n","                return mean_feature\n","            elif self.cfg.pooling == \"attention\":\n","                return attention_feature\n","            elif self.cfg.pooling == \"cls\":\n","                return cls_token_feature\n","            else:\n","                return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        output = self.fc(feature)\n","        return output\n","    \n","class Model2(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","            self.config.hidden_dropout = 0.\n","            self.config.hidden_dropout_prob = 0.\n","            self.config.attention_dropout = 0.\n","            self.config.attention_probs_dropout_prob = 0.\n","            LOGGER.info(self.config)\n","        else:\n","            #self.config = torch.load(config_path)\n","            self.config = AutoConfig.from_pretrained(config_path, output_hidden_states=True)\n","            LOGGER.info(self.config)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel.from_config(self.config)\n","        if self.cfg.gradient_checkpointing:\n","            self.model.gradient_checkpointing_enable()\n","        \n","        if CFG.pooling == 'mean':\n","            self.pool = MeanPooling()\n","        elif CFG.pooling == 'max':\n","            self.pool = MaxPooling()\n","        elif CFG.pooling == 'min':\n","            self.pool = MinPooling()\n","        elif CFG.pooling == 'attention':\n","            self.pool = AttentionPooling(self.config.hidden_size)\n","        elif CFG.pooling == 'weightedlayer':\n","            self.pool = WeightedLayerPooling(self.config.num_hidden_layers, layer_start = CFG.layer_start, layer_weights = None)        \n","\n","        self.fc = nn.Linear(self.config.hidden_size, 6)\n","        self._init_weights(self.fc)\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        output = self.fc(feature)\n","        return output"]},{"cell_type":"markdown","metadata":{"id":"hgudhdp2ibyO"},"source":["# inference"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xqTLZUVfibyO"},"outputs":[],"source":["# ====================================================\n","# inference\n","# ====================================================\n","def inference_fn(test_loader, model, device):\n","    preds = []\n","    model.eval()\n","    model.to(device)\n","    tk0 = tqdm(test_loader, total=len(test_loader))\n","    for inputs in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        preds.append(y_preds.to('cpu').numpy())\n","    predictions = np.concatenate(preds)\n","    return predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mdFvOmMJibyO"},"outputs":[],"source":["final = []\n","for _idx, CFG in enumerate(CFG_list):\n","    test = pd.read_csv('/content/drive/MyDrive/Kaggle Training Results/English Language Learning/data/prev_train.csv', index_col=0).drop_duplicates(subset=['text_id'])\n","    submission = pd.read_csv(\"/content/drive/MyDrive/Kaggle Training Results/English Language Learning/data/prev_train.csv\", index_col=0).drop_duplicates(subset=['text_id'])\n","    # sort by length to speed up inference\n","    test['tokenize_length'] = [len(CFG.tokenizer(text)['input_ids']) for text in test['full_text'].values]\n","    test = test.sort_values('tokenize_length', ascending=True).reset_index(drop=True)\n","\n","    test_dataset = TestDataset(CFG, test)\n","    test_loader = DataLoader(test_dataset,\n","                             batch_size=CFG.batch_size,\n","                             shuffle=False,\n","                             collate_fn=DataCollatorWithPadding(tokenizer=CFG.tokenizer, padding='longest'),\n","                             num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","    predictions = []\n","    for fold in CFG.trn_fold:\n","        if _idx < 6:\n","            model = Model1(CFG, config_path=CFG.config_path, pretrained=False)\n","            state = torch.load(CFG.path+f\"modelfold{fold + 1}normalllrdnomsdnormal.pth\",\n","                           map_location=torch.device('cpu'))\n","            model.load_state_dict(state)\n","        else:\n","            model = Model2(CFG, config_path=CFG.config_path, pretrained=False)\n","            state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                           map_location=torch.device('cpu'))\n","            model.load_state_dict(state['model'])\n","        prediction = inference_fn(test_loader, model, device)\n","        predictions.append(prediction)\n","        del model, state, prediction; gc.collect()\n","        torch.cuda.empty_cache()\n","    predictions = np.mean(predictions, axis=0)\n","    test[CFG.target_cols] = predictions\n","    submission = pd.merge(submission[\"text_id\"], test[[\"text_id\"] + CFG.target_cols], how=\"left\")\n","    final.append(submission[CFG.target_cols].values)\n","    del test, submission, predictions, test_dataset, test_loader; gc.collect()\n","    torch.cuda.empty_cache() "]},{"cell_type":"markdown","metadata":{"id":"ruJtsKyDibyO"},"source":["# Ensemble"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":441},"collapsed":true,"executionInfo":{"elapsed":2990,"status":"ok","timestamp":1669522816333,"user":{"displayName":"Feng Qilong","userId":"09603490936825460639"},"user_tz":-480},"id":"MHOOUKTEibyO","outputId":"672e860c-c0db-4692-8698-69d79ab51375"},"outputs":[{"name":"stdout","output_type":"stream","text":["15142\n"]},{"data":{"text/html":["\n","  <div id=\"df-d56f8d60-5f12-4057-ae47-93a73dbb9dff\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>full_text</th>\n","      <th>cohesion</th>\n","      <th>syntax</th>\n","      <th>vocabulary</th>\n","      <th>phraseology</th>\n","      <th>grammar</th>\n","      <th>conventions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>423A1CA112E2</td>\n","      <td>Phones\\n\\nModern humans today are always on th...</td>\n","      <td>3.056048</td>\n","      <td>3.112964</td>\n","      <td>3.345940</td>\n","      <td>3.206383</td>\n","      <td>3.084330</td>\n","      <td>3.322059</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A8445CABFECE</td>\n","      <td>Phones &amp; Driving\\n\\nDrivers should not be able...</td>\n","      <td>3.710860</td>\n","      <td>3.760511</td>\n","      <td>3.786949</td>\n","      <td>3.763001</td>\n","      <td>3.782464</td>\n","      <td>3.918429</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>6B4F7A0165B9</td>\n","      <td>Cell Phone Operation While Driving\\n\\nThe abil...</td>\n","      <td>4.053563</td>\n","      <td>4.069672</td>\n","      <td>4.481086</td>\n","      <td>4.328255</td>\n","      <td>4.303818</td>\n","      <td>4.165030</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>E05C7F5C1156</td>\n","      <td>People are debating whether if drivers should ...</td>\n","      <td>4.110247</td>\n","      <td>4.031701</td>\n","      <td>4.162265</td>\n","      <td>4.095508</td>\n","      <td>3.993166</td>\n","      <td>4.082003</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>50B3435E475B</td>\n","      <td>Texting and driving\\n\\nOver half of drivers in...</td>\n","      <td>3.845428</td>\n","      <td>3.925613</td>\n","      <td>4.090289</td>\n","      <td>4.076712</td>\n","      <td>4.128270</td>\n","      <td>3.972077</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>15137</th>\n","      <td>0814426B27DF</td>\n","      <td>Most people ask more than one person for advic...</td>\n","      <td>3.305353</td>\n","      <td>3.320829</td>\n","      <td>3.459901</td>\n","      <td>3.451811</td>\n","      <td>3.593226</td>\n","      <td>3.524821</td>\n","    </tr>\n","    <tr>\n","      <th>15138</th>\n","      <td>8F4B595CF9E7</td>\n","      <td>Do you ever want more opinions and options whe...</td>\n","      <td>3.959244</td>\n","      <td>3.955805</td>\n","      <td>4.054248</td>\n","      <td>4.072804</td>\n","      <td>4.118625</td>\n","      <td>4.013373</td>\n","    </tr>\n","    <tr>\n","      <th>15139</th>\n","      <td>6B5809C83978</td>\n","      <td>Has anyone ever gave you advice? Was the advic...</td>\n","      <td>4.187916</td>\n","      <td>4.175071</td>\n","      <td>4.120436</td>\n","      <td>4.159891</td>\n","      <td>4.297247</td>\n","      <td>4.299526</td>\n","    </tr>\n","    <tr>\n","      <th>15140</th>\n","      <td>AFEC37C2D43F</td>\n","      <td>There has been at least one point in everyone'...</td>\n","      <td>4.045924</td>\n","      <td>4.010312</td>\n","      <td>4.133028</td>\n","      <td>4.121380</td>\n","      <td>4.199779</td>\n","      <td>3.930347</td>\n","    </tr>\n","    <tr>\n","      <th>15141</th>\n","      <td>4C471936CD75</td>\n","      <td>In ancient times, and also still today in some...</td>\n","      <td>4.266560</td>\n","      <td>4.200973</td>\n","      <td>4.347042</td>\n","      <td>4.269538</td>\n","      <td>4.350202</td>\n","      <td>4.234642</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>15142 rows × 8 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d56f8d60-5f12-4057-ae47-93a73dbb9dff')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d56f8d60-5f12-4057-ae47-93a73dbb9dff button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d56f8d60-5f12-4057-ae47-93a73dbb9dff');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["            text_id                                          full_text  \\\n","0      423A1CA112E2  Phones\\n\\nModern humans today are always on th...   \n","1      A8445CABFECE  Phones & Driving\\n\\nDrivers should not be able...   \n","2      6B4F7A0165B9  Cell Phone Operation While Driving\\n\\nThe abil...   \n","3      E05C7F5C1156  People are debating whether if drivers should ...   \n","4      50B3435E475B  Texting and driving\\n\\nOver half of drivers in...   \n","...             ...                                                ...   \n","15137  0814426B27DF  Most people ask more than one person for advic...   \n","15138  8F4B595CF9E7  Do you ever want more opinions and options whe...   \n","15139  6B5809C83978  Has anyone ever gave you advice? Was the advic...   \n","15140  AFEC37C2D43F  There has been at least one point in everyone'...   \n","15141  4C471936CD75  In ancient times, and also still today in some...   \n","\n","       cohesion    syntax  vocabulary  phraseology   grammar  conventions  \n","0      3.056048  3.112964    3.345940     3.206383  3.084330     3.322059  \n","1      3.710860  3.760511    3.786949     3.763001  3.782464     3.918429  \n","2      4.053563  4.069672    4.481086     4.328255  4.303818     4.165030  \n","3      4.110247  4.031701    4.162265     4.095508  3.993166     4.082003  \n","4      3.845428  3.925613    4.090289     4.076712  4.128270     3.972077  \n","...         ...       ...         ...          ...       ...          ...  \n","15137  3.305353  3.320829    3.459901     3.451811  3.593226     3.524821  \n","15138  3.959244  3.955805    4.054248     4.072804  4.118625     4.013373  \n","15139  4.187916  4.175071    4.120436     4.159891  4.297247     4.299526  \n","15140  4.045924  4.010312    4.133028     4.121380  4.199779     3.930347  \n","15141  4.266560  4.200973    4.347042     4.269538  4.350202     4.234642  \n","\n","[15142 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["pseudo = pd.read_csv('/content/drive/MyDrive/Kaggle Training Results/English Language Learning/data/prev_train.csv', index_col=0).drop_duplicates(subset=['text_id'])\n","\n","ens = np.clip(np.average(final, weights=weights, axis=0), 1, 5)\n","np.save(\"/content/drive/MyDrive/Kaggle Training Results/English Language Learning/trained/ens.npy\", ens)\n","print(len(ens))\n","\n","#ens = (sub1 + sub2)/(CFG1.weight + CFG2.weight)\n","\n","pseudo[CFG1.target_cols] = ens\n","display(pseudo)\n","pseudo.to_csv(f'/content/drive/MyDrive/Kaggle Training Results/English Language Learning/trained/pseudo.csv', index=False)"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":0}
