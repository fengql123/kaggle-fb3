{"cells":[{"cell_type":"markdown","metadata":{"id":"FCSr5bT88rKR"},"source":["### Imports"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5131,"status":"ok","timestamp":1669780109740,"user":{"displayName":"Feng Qilong","userId":"09603490936825460639"},"user_tz":-480},"id":"S0jVYCDr8uLG"},"outputs":[],"source":["import os\n","import gc\n","import re\n","import ast\n","import sys\n","import copy\n","import json\n","import time\n","import math\n","import string\n","import pickle\n","import random\n","import joblib\n","import itertools\n","\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","from tqdm.auto import tqdm\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","import torch\n","import torch.nn as nn\n","from torch.nn import Parameter\n","import torch.nn.functional as F\n","from torch.optim import Adam, SGD, AdamW\n","from torch.utils.data import DataLoader, Dataset\n","from torch.optim.swa_utils import AveragedModel, update_bn, SWALR\n","import tokenizers\n","import transformers\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{"id":"ngS-h9H_8yFx"},"source":["### CFG"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":478,"status":"ok","timestamp":1669781159793,"user":{"displayName":"Feng Qilong","userId":"09603490936825460639"},"user_tz":-480},"id":"BzYM7ag28waJ"},"outputs":[],"source":["class CFG:\n","    model=\"microsoft/deberta-v3-base\" # funnel-transformer/medium, funnel-transformer/large, google/bigbird-roberta-base, google/bigbird-roberta-large, roberta-large, roberta-base, microsoft/deberta-v3-base, microsoft/deberta-v3-large, google/electra-base-discriminator, google/electra-large-discriminator, xlm-roberta-base, xlm-roberta-large, xlnet-base-cased, xlnet-large-cased\n","    model_name=\"\".join((\"-\".join(model.split(\"/\"))).split(\"-\"))\n","    gradient_checkpointing=False\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps_rate=0.0\n","    apex=True\n","    epochs=1\n","    encoder_lr=5e-5\n","    decoder_lr=5e-4\n","    min_lr=1e-6\n","    eps=1e-6\n","    betas=(0.9, 0.999)\n","    batch_size=8\n","    max_len=512\n","    weight_decay=0.01\n","    gradient_accumulation_steps=1\n","    grad_clipping=True\n","    max_grad_norm=1000\n","    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n","    seed=42\n","    n_fold=4\n","    trn_fold=range(n_fold)\n","    num_workers=8\n","    eval_method=\"epoch\" # step, epoch\n","    eval_step=30\n","    reinit_layers=1\n","    init_weight=\"normal\" # xavier_uniform, xavier_normal, kaiming_uniform, kaiming_normal, orthogonal, normal\n","    pooling=\"mean\" # mean, attention, cls, concat\n","    llrd=\"normal\" # grouped, normal, none\n","    llr_decay=0.8\n","    msd_num=5\n","    msd=False \n","    train=True\n","    swa=False\n","    swa_start_ratio=0.75\n","    swa_lr=1e-4\n","    anneal_epochs=int(1-swa_start_ratio * epochs)\n","    anneal_strategy='cos'\n","    fgm=False\n","    unscale=True\n","    wandb=False\n","    debug=False\n","    pseudo=False\n","\n","if CFG.debug:\n","  CFG.epochs=2\n","    \n","DATA_DIR = \"/content/drive/MyDrive/Kaggle Training Results/English Language Learning/data/\"\n","OUTPUT_DIR = f\"/content/drive/MyDrive/Kaggle Training Results/English Language Learning/trained/{CFG.model_name}{CFG.pooling}pooling/\""]},{"cell_type":"markdown","metadata":{"id":"t_ig4Ery9Z5K"},"source":["### Helper Functions"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1669781160287,"user":{"displayName":"Feng Qilong","userId":"09603490936825460639"},"user_tz":-480},"id":"SdRMVnMl9cVg"},"outputs":[],"source":["def MCRMSE(y_trues, y_preds):\n","    scores = []\n","    idxes = y_trues.shape[1]\n","    for i in range(idxes):\n","        y_true = y_trues[:,i]\n","        y_pred = y_preds[:,i]\n","        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n","        scores.append(score)\n","    mcrmse_score = np.mean(scores)\n","    return mcrmse_score, scores\n","\n","\n","def get_score(y_trues, y_preds):\n","    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n","    return mcrmse_score, scores\n","\n","def cv_split(func):\n","    fold = func(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n","    return fold\n","\n","def seed_everything(seed = 42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    \n","seed_everything(seed=CFG.seed)"]},{"cell_type":"markdown","metadata":{"id":"fCCNap-V9nD9"},"source":["### Load Data"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":511},"executionInfo":{"elapsed":567,"status":"ok","timestamp":1669781160849,"user":{"displayName":"Feng Qilong","userId":"09603490936825460639"},"user_tz":-480},"id":"rJs5CCU49pMQ","outputId":"98744e44-3e84-43fd-ab9f-c737d36bf69f"},"outputs":[{"name":"stdout","output_type":"stream","text":["train.shape: (3911, 8)\n"]},{"data":{"text/html":["\n","  <div id=\"df-cde01ef0-f806-42ae-ac69-505078ce715c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>full_text</th>\n","      <th>cohesion</th>\n","      <th>syntax</th>\n","      <th>vocabulary</th>\n","      <th>phraseology</th>\n","      <th>grammar</th>\n","      <th>conventions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0016926B079C</td>\n","      <td>I think that students would benefit from learn...</td>\n","      <td>3.5</td>\n","      <td>3.5</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0022683E9EA5</td>\n","      <td>When a problem is a change you have to let it ...</td>\n","      <td>2.5</td>\n","      <td>2.5</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00299B378633</td>\n","      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n","      <td>3.0</td>\n","      <td>3.5</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>2.5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>003885A45F42</td>\n","      <td>The best time in life is when you become yours...</td>\n","      <td>4.5</td>\n","      <td>4.5</td>\n","      <td>4.5</td>\n","      <td>4.5</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0049B1DF5CCC</td>\n","      <td>Small act of kindness can impact in other peop...</td>\n","      <td>2.5</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>2.5</td>\n","      <td>2.5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cde01ef0-f806-42ae-ac69-505078ce715c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-cde01ef0-f806-42ae-ac69-505078ce715c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-cde01ef0-f806-42ae-ac69-505078ce715c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["        text_id                                          full_text  cohesion  \\\n","0  0016926B079C  I think that students would benefit from learn...       3.5   \n","1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n","2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n","3  003885A45F42  The best time in life is when you become yours...       4.5   \n","4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n","\n","   syntax  vocabulary  phraseology  grammar  conventions  \n","0     3.5         3.0          3.0      4.0          3.0  \n","1     2.5         3.0          2.0      2.0          2.5  \n","2     3.5         3.0          3.0      3.0          2.5  \n","3     4.5         4.5          4.5      4.0          5.0  \n","4     3.0         3.0          3.0      2.5          2.5  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["test.shape: (3, 2)\n"]},{"data":{"text/html":["\n","  <div id=\"df-7a7cff95-6e0f-4ce6-93cb-2c4aa22846f0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>full_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0000C359D63E</td>\n","      <td>when a person has no experience on a job their...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000BAD50D026</td>\n","      <td>Do you think students would benefit from being...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00367BB2546B</td>\n","      <td>Thomas Jefferson once states that \"it is wonde...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a7cff95-6e0f-4ce6-93cb-2c4aa22846f0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7a7cff95-6e0f-4ce6-93cb-2c4aa22846f0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7a7cff95-6e0f-4ce6-93cb-2c4aa22846f0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["        text_id                                          full_text\n","0  0000C359D63E  when a person has no experience on a job their...\n","1  000BAD50D026  Do you think students would benefit from being...\n","2  00367BB2546B  Thomas Jefferson once states that \"it is wonde..."]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["submission.shape: (3, 7)\n"]},{"data":{"text/html":["\n","  <div id=\"df-4fca776a-825c-4fb3-bbed-1c227811f089\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>cohesion</th>\n","      <th>syntax</th>\n","      <th>vocabulary</th>\n","      <th>phraseology</th>\n","      <th>grammar</th>\n","      <th>conventions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0000C359D63E</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000BAD50D026</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00367BB2546B</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4fca776a-825c-4fb3-bbed-1c227811f089')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4fca776a-825c-4fb3-bbed-1c227811f089 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4fca776a-825c-4fb3-bbed-1c227811f089');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["        text_id  cohesion  syntax  vocabulary  phraseology  grammar  \\\n","0  0000C359D63E       3.0     3.0         3.0          3.0      3.0   \n","1  000BAD50D026       3.0     3.0         3.0          3.0      3.0   \n","2  00367BB2546B       3.0     3.0         3.0          3.0      3.0   \n","\n","   conventions  \n","0          3.0  \n","1          3.0  \n","2          3.0  "]},"metadata":{},"output_type":"display_data"}],"source":["train = pd.read_csv(DATA_DIR + \"train.csv\")\n","test = pd.read_csv(DATA_DIR + \"test.csv\")\n","submission = pd.read_csv(DATA_DIR + \"sample_submission.csv\")\n","\n","print(f\"train.shape: {train.shape}\")\n","display(train.head())\n","print(f\"test.shape: {test.shape}\")\n","display(test.head())\n","print(f\"submission.shape: {submission.shape}\")\n","display(submission.head())"]},{"cell_type":"markdown","metadata":{"id":"LRO-GNLT92L9"},"source":["### Tokenizer"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1902,"status":"ok","timestamp":1669781162750,"user":{"displayName":"Feng Qilong","userId":"09603490936825460639"},"user_tz":-480},"id":"UwRAKRK191mQ","outputId":"288cc7af-42ff-4cea-a203-eb638e035bb3"},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"text/plain":["('/content/drive/MyDrive/Kaggle Training Results/English Language Learning/trained/microsoftdebertav3basemeanpooling/tokenizer/tokenizer_config.json',\n"," '/content/drive/MyDrive/Kaggle Training Results/English Language Learning/trained/microsoftdebertav3basemeanpooling/tokenizer/special_tokens_map.json',\n"," '/content/drive/MyDrive/Kaggle Training Results/English Language Learning/trained/microsoftdebertav3basemeanpooling/tokenizer/spm.model',\n"," '/content/drive/MyDrive/Kaggle Training Results/English Language Learning/trained/microsoftdebertav3basemeanpooling/tokenizer/added_tokens.json',\n"," '/content/drive/MyDrive/Kaggle Training Results/English Language Learning/trained/microsoftdebertav3basemeanpooling/tokenizer/tokenizer.json')"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","CFG.tokenizer = tokenizer\n","tokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')"]},{"cell_type":"markdown","metadata":{"id":"5bfZLAXF9rSo"},"source":["### CV Split"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121},"executionInfo":{"elapsed":819,"status":"ok","timestamp":1669781163563,"user":{"displayName":"Feng Qilong","userId":"09603490936825460639"},"user_tz":-480},"id":"4Uz6NDpu9tuP","outputId":"74fbe16a-32fc-4280-c5e5-e251e078cf4b"},"outputs":[{"data":{"text/plain":["fold\n","0    979\n","1    979\n","2    972\n","3    981\n","dtype: int64"]},"metadata":{},"output_type":"display_data"}],"source":["Fold = MultilabelStratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n","df = train.copy()\n","y = pd.get_dummies(data=df[CFG.target_cols], columns=CFG.target_cols)\n","for n, (train_index, val_index) in enumerate(Fold.split(X=train, y=y)):\n","        train.loc[val_index, 'fold'] = int(n)\n","train['fold'] = train['fold'].astype(int)\n","display(train.groupby('fold').size())\n","train.to_csv(DATA_DIR + \"folded_train.csv\")"]},{"cell_type":"markdown","metadata":{"id":"VczJyBPB96HC"},"source":["### Dataset"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1669781163563,"user":{"displayName":"Feng Qilong","userId":"09603490936825460639"},"user_tz":-480},"id":"rcE1tP-Y97vb","outputId":"c9f76c21-733a-49ae-af81-ec69bae31129"},"outputs":[{"name":"stdout","output_type":"stream","text":["max_len: 1428\n"]}],"source":["if \"bigbird\" in CFG.model or \"deberta\" in CFG.model or \"longformer\" in CFG.model:\n","    CFG.max_len = 1428\n","print(f\"max_len: {CFG.max_len}\")"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1669781163564,"user":{"displayName":"Feng Qilong","userId":"09603490936825460639"},"user_tz":-480},"id":"Su8VSDLT9-cY"},"outputs":[],"source":["def prepare_input(cfg, text):\n","    inputs = cfg.tokenizer.encode_plus(\n","        text, \n","        return_tensors=None, \n","        add_special_tokens=True, \n","        max_length=CFG.max_len,\n","        pad_to_max_length=True,\n","        truncation=True\n","    )\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.texts = df['full_text'].values\n","        self.labels = df[cfg.target_cols].values\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, i):\n","        inputs = prepare_input(self.cfg, self.texts[i])\n","        label = torch.tensor(self.labels[i], dtype=torch.float)\n","        return inputs, label\n","    \n","\n","def collate(inputs):\n","    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n","    for k, v in inputs.items():\n","        inputs[k] = inputs[k][:,:mask_len]\n","    return inputs"]},{"cell_type":"markdown","metadata":{"id":"y9i_vZzFRDzi"},"source":["### Pooling"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1669781163564,"user":{"displayName":"Feng Qilong","userId":"09603490936825460639"},"user_tz":-480},"id":"evdNPr4yRC5S"},"outputs":[],"source":["class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings\n","\n","class AttentionPooling(nn.Module):\n","    def __init__(self, in_dim):\n","        super().__init__()\n","        self.attention = nn.Sequential(\n","        nn.Linear(in_dim, in_dim),\n","        nn.LayerNorm(in_dim),\n","        nn.GELU(),\n","        nn.Linear(in_dim, 1),\n","        )\n","\n","    def forward(self, last_hidden_state, attention_mask):\n","        w = self.attention(last_hidden_state).float()\n","        w[attention_mask==0]=float('-inf')\n","        w = torch.softmax(w,1)\n","        attention_embeddings = torch.sum(w * last_hidden_state, dim=1)\n","        return attention_embeddings"]},{"cell_type":"markdown","metadata":{"id":"AB8P1SAURIly"},"source":["### FGM"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1669781163564,"user":{"displayName":"Feng Qilong","userId":"09603490936825460639"},"user_tz":-480},"id":"XhIjXNdKRKoS"},"outputs":[],"source":["class FGM():\n","    def __init__(self, model):\n","        self.model = model\n","        self.backup = {}\n","\n","    def attack(self, epsilon = 1., emb_name = 'word_embeddings'):\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and emb_name in name:\n","                self.backup[name] = param.data.clone()\n","                norm = torch.norm(param.grad)\n","                if norm != 0:\n","                    r_at = epsilon * param.grad / norm\n","                    param.data.add_(r_at)\n","\n","    def restore(self, emb_name = 'word_embeddings'):\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and emb_name in name:\n","                assert name in self.backup\n","                param.data = self.backup[name]\n","            self.backup = {}"]},{"cell_type":"markdown","metadata":{"id":"9Q39Ijr3-KML"},"source":["### Model"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1669781163564,"user":{"displayName":"Feng Qilong","userId":"09603490936825460639"},"user_tz":-480},"id":"h4W7qf0S-JC7"},"outputs":[],"source":["class Model(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","            self.config.hidden_dropout = 0.\n","            self.config.hidden_dropout_prob = 0.\n","            self.config.attention_dropout = 0.\n","            self.config.attention_probs_dropout_prob = 0.\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel.from_config(self.config)\n","        if self.cfg.gradient_checkpointing:\n","            self.model.gradient_checkpointing_enable()\n","        \n","        self.pool = MeanPooling()\n","        self.attention = AttentionPooling(self.config.hidden_size)\n","        self.high_dropout = nn.Dropout(p=0.5)\n","        self.concat_pool = nn.Linear(self.config.hidden_size*3, self.config.hidden_size)\n","        self.fc = nn.Linear(self.config.hidden_size, 6)\n","        self._init_weights(self.fc)\n","        self._init_weights(self.concat_pool)\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            if CFG.init_weight == 'normal':\n","                module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            elif CFG.init_weight == 'xavier_uniform':\n","                module.weight.data = nn.init.xavier_uniform_(module.weight.data)\n","            elif CFG.init_weight == 'xavier_normal':\n","                module.weight.data = nn.init.xavier_normal_(module.weight.data)\n","            elif CFG.init_weight == 'kaiming_uniform':\n","                module.weight.data = nn.init.kaiming_uniform_(module.weight.data)\n","            elif CFG.init_weight == 'kaiming_normal':\n","                module.weight.data = nn.init.kaiming_normal_(module.weight.data)\n","            elif CFG.init_weight == 'orthogonal':\n","                module.weight.data = nn.init.orthogonal_(module.weight.data) \n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            if CFG.init_weight == 'normal':\n","                module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            elif CFG.init_weight == 'xavier_uniform':\n","                module.weight.data = nn.init.xavier_uniform_(module.weight.data)\n","            elif CFG.init_weight == 'xavier_normal':\n","                module.weight.data = nn.init.xavier_normal_(module.weight.data)\n","            elif CFG.init_weight == 'kaiming_uniform':\n","                module.weight.data = nn.init.kaiming_uniform_(module.weight.data)\n","            elif CFG.init_weight == 'kaiming_normal':\n","                module.weight.data = nn.init.kaiming_normal_(module.weight.data)\n","            elif CFG.init_weight == 'orthogonal':\n","                module.weight.data = nn.init.orthogonal_(module.weight.data) \n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs.last_hidden_state\n","\n","        if self.cfg.msd:\n","            mean_feature = torch.mean(torch.stack([self.pool(self.high_dropout(last_hidden_states), inputs['attention_mask']) for _ in range(self.cfg.msd_num)], dim=0), dim=0)    \n","            attention_feature = torch.mean(torch.stack([self.attention(self.high_dropout(last_hidden_states), inputs['attention_mask']) for _ in range(self.cfg.msd_num)], dim=0), dim=0)  \n","            cls_token_feature = torch.mean(torch.stack([self.high_dropout(last_hidden_states)[:, 0, :] for _ in range(self.cfg.msd_num)], dim=0), dim=0)\n","            combine_feature = torch.cat([mean_feature, attention_feature, cls_token_feature], dim = -1)\n","            feature = self.concat_pool(combine_feature)\n","            if self.cfg.pooling == \"mean\":\n","                return mean_feature\n","            elif self.cfg.pooling == \"attention\":\n","                return attention_feature\n","            elif self.cfg.pooling == \"cls\":\n","                return cls_token_feature\n","            else:\n","                return feature\n","        else:\n","        # mean pooled sentence representation\n","            mean_feature = self.pool(last_hidden_states, inputs['attention_mask'])\n","        # attention based sentence representation\n","            attention_feature = self.attention(last_hidden_states, inputs['attention_mask'])\n","        # CLS Token representation\n","            cls_token_feature = last_hidden_states[:, 0, :] # only cls token\n","        # Concat them\n","            combine_feature = torch.cat([mean_feature, attention_feature, cls_token_feature], dim = -1)\n","        # MLP\n","            feature = self.concat_pool(combine_feature)\n","            if self.cfg.pooling == \"mean\":\n","                return mean_feature\n","            elif self.cfg.pooling == \"attention\":\n","                return attention_feature\n","            elif self.cfg.pooling == \"cls\":\n","                return cls_token_feature\n","            else:\n","                return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        output = self.fc(feature)\n","        return output"]},{"cell_type":"markdown","metadata":{"id":"z-zCdABL-oLe"},"source":["### Train"]},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1669781163565,"user":{"displayName":"Feng Qilong","userId":"09603490936825460639"},"user_tz":-480},"id":"QVgI9A5k-nck"},"outputs":[],"source":["def re_initializing_layer(model, config, layer_num):\n","    print(f\"reinitializing last {layer_num} layers\")\n","    for module in model.model.encoder.layer[-layer_num:].modules():\n","        if isinstance(module, nn.Linear):\n","            if CFG.init_weight == 'normal':\n","                module.weight.data.normal_(mean=0.0, std=config.initializer_range)\n","            elif CFG.init_weight == 'xavier_uniform':\n","                module.weight.data = nn.init.xavier_uniform_(module.weight.data)\n","            elif CFG.init_weight == 'xavier_normal':\n","                module.weight.data = nn.init.xavier_normal_(module.weight.data)\n","            elif CFG.init_weight == 'kaiming_uniform':\n","                module.weight.data = nn.init.kaiming_uniform_(module.weight.data)\n","            elif CFG.init_weight == 'kaiming_normal':\n","                module.weight.data = nn.init.kaiming_normal_(module.weight.data)\n","            elif CFG.init_weight == 'orthogonal':\n","                module.weight.data = nn.init.orthogonal_(module.weight.data) \n","                \n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            if CFG.init_weight == 'normal':\n","                module.weight.data.normal_(mean=0.0, std=config.initializer_range)\n","            elif CFG.init_weight == 'xavier_uniform':\n","                module.weight.data = nn.init.xavier_uniform_(module.weight.data)\n","            elif CFG.init_weight == 'xavier_normal':\n","                module.weight.data = nn.init.xavier_normal_(module.weight.data)\n","            elif CFG.init_weight == 'kaiming_uniform':\n","                module.weight.data = nn.init.kaiming_uniform_(module.weight.data)\n","            elif CFG.init_weight == 'kaiming_normal':\n","                module.weight.data = nn.init.kaiming_normal_(module.weight.data)\n","            elif CFG.init_weight == 'orthogonal':\n","                module.weight.data = nn.init.orthogonal_(module.weight.data)\n","                \n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","    return model\n","\n","def train_func(global_step, batch, model, criterion, optimizer, scheduler, scaler, fgm, swa_model, swa_scheduler, device):\n","    x, y = batch\n","    x = collate(x)\n","    for k,v in x.items():\n","        x[k] = v.to(device)\n","    y = y.to(device)\n","    optimizer.zero_grad()\n","    with torch.cuda.amp.autocast(enabled=CFG.apex):\n","        yhat = model(x)\n","        loss = criterion(yhat, y)\n","    if CFG.gradient_accumulation_steps > 1:\n","        loss = loss / CFG.gradient_accumulation_steps\n","    scaler.scale(loss).backward()\n","    if CFG.unscale:\n","        scaler.unscale_(optimizer)\n","    if CFG.grad_clipping:\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","    if CFG.fgm:\n","        fgm.attack()\n","        with torch.cuda.amp.autocast(enabled = CFG.apex):\n","            y_preds = model(x)\n","            loss_adv = criterion(y_preds, y)\n","            loss_adv.backward()\n","        fgm.restore()\n","    scaler.step(optimizer)\n","    scaler.update()\n","    if not CFG.swa:\n","        scheduler.step()\n","    else:\n","        if global_step < CFG.swa_start:\n","            scheduler.step()\n","        else:\n","            swa_model.update_parameters(model)\n","            swa_scheduler.step()\n","\n","    return yhat, y, loss\n","\n","def val(val_loader, model, criterion, device):\n","    count = 0\n","    mean_loss = 0\n","    \n","    model.eval()\n","    preds = []\n","    for batch in val_loader:\n","        with torch.inference_mode():\n","            count += 1\n","            x, y = batch\n","            x = collate(x)\n","            for k,v in x.items():\n","              x[k] = v.to(device)\n","            y = y.to(device)\n","            yhat = model(x)\n","            loss = criterion(yhat, y)\n","            if CFG.gradient_accumulation_steps > 1:\n","              loss = loss / CFG.gradient_accumulation_steps\n","            preds.append(yhat.to('cpu').numpy())\n","            mean_loss += loss\n","    mean_loss = mean_loss/count\n","    predictions = np.concatenate(preds)\n","    return mean_loss, predictions\n","\n","def train_and_eval(batch, val_loader, val_labels, val_folds, global_step, best_score, model, criterion, optimizer, scheduler, progress_bar, scaler, fgm, swa_model, swa_scheduler, device, fold):\n","    yhat, y, training_loss = train_func(global_step, batch, model, criterion, optimizer, scheduler, scaler, fgm, swa_model, swa_scheduler, device)\n","    training_score, training_scores = get_score(yhat.cpu().detach().numpy(), y.cpu().detach().numpy())\n","    progress_bar.update(1)\n","\n","    if global_step % CFG.eval_step == 0:\n","        val_loss, predictions = val(val_loader, model, criterion, device)\n","        val_score, val_scores = get_score(val_labels, predictions)\n","        print(\"=\" * 30)\n","        print(f\"step {global_step} | training loss: {training_loss} | training score: {training_score} | validation loss: {val_loss} | validation score: {val_score}\")\n","        if val_score < best_score:\n","            best_score = val_score\n","            val_folds[[f\"pred_{c}\" for c in CFG.target_cols]] = predictions\n","            if not CFG.debug:\n","                print(f\"saving best model with score: {best_score}\")\n","                if CFG.msd:\n","                    torch.save(model.state_dict(), OUTPUT_DIR + f\"modelfold{fold + 1}{CFG.llrd}llrdmsd{CFG.init_weight}.pth\")\n","                else:\n","                    torch.save(model.state_dict(), OUTPUT_DIR + f\"modelfold{fold + 1}{CFG.llrd}llrdnomsd{CFG.init_weight}.pth\")\n","        print(\"=\" * 30)\n","        print()\n","    \n","    if CFG.wandb and not CFG.debug:\n","        wandb.log(\n","            {f\"[fold{fold}] training loss\": training_loss}\n","        )\n","    \n","    return best_score, val_folds, training_loss\n","\n","def train_and_eval_epoch(train_loader, val_loader, val_labels, val_folds, best_score, model, criterion, optimizer, epoch, scheduler, fgm, swa_model, swa_scheduler, progress_bar, device, global_step, fold):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    mean_training_loss = 0\n","    for batch in train_loader:\n","        global_step += 1\n","        best_score, val_folds, training_loss = train_and_eval(batch, val_loader, val_labels, val_folds, global_step, best_score, model, criterion, optimizer, scheduler, progress_bar, scaler, fgm, swa_model, swa_scheduler, device, fold)\n","        mean_training_loss += training_loss\n","    mean_training_loss = mean_training_loss / len(train_loader)\n","    return global_step, val_folds, best_score, mean_training_loss\n","\n","\n","def train_loop(train, fold):\n","    print(f\"============== fold: {fold + 1} training ==============\")\n","    train_folds = train[train['fold'] != fold].reset_index(drop=True)\n","    if CFG.pseudo:\n","        pseudo = pd.read_csv(\"/content/drive/MyDrive/Kaggle Training Results/English Language Learning/trained/pseudo.csv\", index_col=0)\n","        pseudo[\"fold\"] = [-1] * len(pseudo)\n","        train_folds = pd.concat([train_folds, pseudo])\n","    val_folds = train[train['fold'] == fold].reset_index(drop=True)\n","    val_labels = val_folds[CFG.target_cols].values\n","\n","    \n","    train_dataset = TrainDataset(CFG, train_folds)\n","    val_dataset = TrainDataset(CFG, val_folds)\n","    \n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=True,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=True\n","        )\n","    val_loader = DataLoader(\n","        val_dataset,\n","        batch_size=CFG.batch_size * 2,\n","        shuffle=False,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=False\n","        )\n","    \n","    reinit_layers = CFG.reinit_layers\n","    model = Model(CFG, pretrained=True)\n","\n","    if reinit_layers > 0 and \"funnel\" not in CFG.model:\n","      model = re_initializing_layer(model, model.config, reinit_layers)\n","    torch.save(model.config, OUTPUT_DIR+\"config.pth\")\n","    model.to(device)\n","    \n","    def get_optimizer_params_groupedllrd(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","      no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","      total_layers = int(model.config.num_hidden_layers)\n","      group_layers = int(total_layers/4)\n","      group1 = [f\"layer.{i}.\" for i in range(group_layers)]\n","      group2 = [f\"layer.{i}.\" for i in range(group_layers, group_layers*2)]\n","      group3 = [f\"layer.{i}.\" for i in range(group_layers*2, total_layers)]\n","      optimizer_parameters = [\n","            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group1)],\n","             'lr': encoder_lr/3, 'weight_decay': weight_decay},\n","             {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group2)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","             {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group3)],\n","             'lr': encoder_lr*3.5, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group1)],\n","             'lr': encoder_lr/3, 'weight_decay': 0.0},\n","             {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group2)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","             {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group3)],\n","             'lr': encoder_lr*3.5, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","             'lr': encoder_lr*10, 'weight_decay': 0.0}\n","      ]\n","      return optimizer_parameters\n","\n","    def get_optimizer_params_llrd(model, encoder_lr, decoder_lr, weight_decay, llr_decay):\n","      no_decay = [\"bias\", \"LayerNorm.weight\"]\n","      optimizer_grouped_parameters = [\n","        {\n","            \"params\": [p for n, p in model.named_parameters() if \"model\" not in n],\n","            \"lr\": decoder_lr,\n","            \"weight_decay\": 0.0,\n","        }\n","      ]\n","      layers = [model.model.embeddings] + list(model.model.encoder.layer)\n","      layers.reverse()\n","      lr = encoder_lr\n","      for layer in layers:\n","        optimizer_grouped_parameters += [\n","            {\n","                \"params\": [p for n, p in layer.named_parameters() if not any(nd in n for nd in no_decay)],\n","                \"weight_decay\": weight_decay,\n","                \"lr\": lr,\n","            },\n","            {\n","                \"params\": [p for n, p in layer.named_parameters() if any (nd in n for nd in no_decay)],\n","                \"weight_decay\": 0.0,\n","                \"lr\": lr,\n","            }\n","        ]\n","        lr *= llr_decay\n","      return optimizer_grouped_parameters\n","\n","    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","      param_optimizer = list(model.named_parameters())\n","      no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","      optimizer_parameters = [\n","            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","             'lr': decoder_lr, 'weight_decay': 0.0}\n","      ]\n","      return optimizer_parameters\n","\n","\n","    if CFG.llrd == \"grouped\":\n","      optimizer_parameters = get_optimizer_params_groupedllrd(model,\n","                                                  encoder_lr=CFG.encoder_lr, \n","                                                  decoder_lr=CFG.decoder_lr,\n","                                                  weight_decay=CFG.weight_decay)\n","    elif CFG.llrd == \"normal\":\n","      optimizer_parameters = get_optimizer_params_llrd(model,\n","                                                  encoder_lr=CFG.encoder_lr, \n","                                                  decoder_lr=CFG.decoder_lr,\n","                                                  weight_decay=CFG.weight_decay,\n","                                                  llr_decay = CFG.llr_decay)\n","    else:\n","      optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr, \n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","\n","\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","    \n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=int(cfg.num_warmup_steps_rate * num_train_steps), num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=int(cfg.num_warmup_steps_rate * num_train_steps), num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","    \n","    num_steps_total = CFG.epochs * len(train_loader)\n","\n","    # FGM\n","    fgm = FGM(model)\n","\n","    # SWA\n","    swa_model = AveragedModel(model)\n","    swa_scheduler = SWALR(\n","        optimizer,\n","        swa_lr=CFG.swa_lr,\n","        anneal_strategy=CFG.anneal_strategy\n","    )\n","    CFG.swa_start = CFG.swa_start_ratio * num_steps_total\n","    \n","    if CFG.eval_method == \"epoch\":\n","        CFG.eval_step = len(train_loader)\n","    num_steps_val = len(val_loader)\n","    \n","    scheduler = get_scheduler(CFG, optimizer, int(CFG.epochs * len(train_loader)))\n","    criterion = nn.SmoothL1Loss(reduction='mean')\n","    \n","    progress_bar_train = tqdm(range(num_steps_total))\n","    global_step = 0\n","    best_score = np.inf\n","    \n","    for epoch in range(CFG.epochs):\n","        global_step, val_folds, best_score, mean_training_loss = train_and_eval_epoch(train_loader, val_loader, val_labels, val_folds, best_score, model, criterion, optimizer, epoch, scheduler, fgm, swa_model, swa_scheduler, progress_bar_train, device, global_step, fold)\n","        print(f\"best score after epoch {epoch + 1} : {best_score} | training loss: {mean_training_loss}\")\n","    \n","    if CFG.swa:\n","        update_bn(train_loader, swa_model, device=torch.device('cuda'))\n","        mean_loss, predictions = val(val_loader, swa_model, criterion, device)\n","        swa_score = get_score(val_labels, predictions)\n","        print(f\"SWA score: {swa_score}\")\n","        if swa_score < best_score:\n","            print(f\"saving model with score: {best_score}\")\n","            if CFG.msd:\n","                torch.save(swa_model.state_dict(), OUTPUT_DIR + f\"modelfold{fold + 1}{CFG.llrd}llrdmsd{CFG.init_weight}.pth\")\n","            else:\n","                torch.save(swa_model.state_dict(), OUTPUT_DIR + f\"modelfold{fold + 1}{CFG.llrd}llrdnomsd{CFG.init_weight}.pth\")\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    return val_folds"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":998,"referenced_widgets":["a7c46cc8ac784b9e91958e5734add3c0","bd44e8e3584f4fd1af565eadac329fae","6579b5dfab69442488128218447658fe","91a42b3a97674e359c1084d3aa510cc3","042bc26178994d4fadd3bb0d7ebdaad1","91b66c9d4c024cf3a595e6fcf7a19099","d447ad55851043b0b56ff47d2ce754ca","3326acebbea443189aeb6139da42a98d","f9a7c90026764dd2a7cf49194873e0f8","2ffb08dd4296480180a494c556fbf4d9","2160dc67bf9243bfaab8d190e080f6cc","7d9777ccb696402c929a79905723bf25","d02ea1a0b938483082a9e08bd1f5dbc4","7005d4b808274b7c85dde7bd08df6ee9","accefc9784b94e25a4c0154885b553fb","73f60470dbea40c0be460a45fb526e93","ed26737a317b42a8b7a6bd08558122b6","cc4122c7dab244a999cd03a2d4164118","392e7609d8a74a4699128cdc0df9668f","ef7d312d535f4da1926b4c61aa36b322","61ac1ac30c2744b5a7e900c352ec62b7","ee8ec12f1e05411d808096fa48c9f7d0","9804037822044844932576e4bee1d1db","0bc74cebb82c414db3b473ca2fd4c4f1","1268f2beb6ce4cc8899d5a82e16bb7c2","a350ba65cb5b40e383e13a2a318e2503","e29b17c5440c401ca683361192c86bed","bd4e5c615a474a258531b48a49f1184f","04d720b4ccc1414fb8e439a2efe65f37","e840e22885814101990b06fb4b3acb7b","79247e87089b4d319e1e5076d2fa9d29","df3a0dd5662848b894124aafe0c1b3d9","28a8fc3d8a5f4c3fa0e8a73a669dcaab","1464849830154d74a16d4b0c56346464","99a2821339094ed39aaeff1e412af5be","cc2293455f89418b8089e07ac491574b","820da2578b1e4634bc72f99f531df89f","b5b135336de449569ba31345084f44c9","1f0de55dbfc241bea6304991c6f8167a","5083106fac8047ffa4c40fad9fd6b45c","3440b0e704f348ec9af824f8dc29c4a3","7e2ab252e2074792bb3b7db9d08dec3a","d0cd15c74c97491da98365bc9bf505a7","30defcfb755848db8c0828ceb78c0ce4"]},"executionInfo":{"elapsed":713929,"status":"ok","timestamp":1669781877487,"user":{"displayName":"Feng Qilong","userId":"09603490936825460639"},"user_tz":-480},"id":"dRZUjiF8AAAw","outputId":"12f17856-bfd6-4ad3-e034-5541dc23605d"},"outputs":[{"name":"stdout","output_type":"stream","text":["============== fold: 1 training ==============\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["reinitializing last 1 layers\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a7c46cc8ac784b9e91958e5734add3c0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/366 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["==============================\n","step 366 | training loss: 0.16973647475242615 | training score: 0.5615291595458984 | validation loss: 0.11985740065574646 | validation score: 0.4935551053332832\n","saving best model with score: 0.4935551053332832\n","==============================\n","\n","best score after epoch 1 : 0.4935551053332832 | training loss: 0.21864551305770874\n","+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","============== fold: 2 training ==============\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["reinitializing last 1 layers\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7d9777ccb696402c929a79905723bf25","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/366 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["==============================\n","step 366 | training loss: 0.1444847583770752 | training score: 0.5284966826438904 | validation loss: 0.11282975226640701 | validation score: 0.47561079273025114\n","saving best model with score: 0.47561079273025114\n","==============================\n","\n","best score after epoch 1 : 0.47561079273025114 | training loss: 0.180236354470253\n","+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","============== fold: 3 training ==============\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["reinitializing last 1 layers\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9804037822044844932576e4bee1d1db","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/367 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["==============================\n","step 367 | training loss: 0.1549607515335083 | training score: 0.5432860851287842 | validation loss: 0.1263970285654068 | validation score: 0.5060120220619165\n","saving best model with score: 0.5060120220619165\n","==============================\n","\n","best score after epoch 1 : 0.5060120220619165 | training loss: 0.2148781269788742\n","+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","============== fold: 4 training ==============\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["reinitializing last 1 layers\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1464849830154d74a16d4b0c56346464","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/366 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["==============================\n","step 366 | training loss: 0.12016137689352036 | training score: 0.48696354031562805 | validation loss: 0.1208503320813179 | validation score: 0.49383887790481107\n","saving best model with score: 0.49383887790481107\n","==============================\n","\n","best score after epoch 1 : 0.49383887790481107 | training loss: 0.20390519499778748\n","+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"]}],"source":["if CFG.train:\n","    oof_df = pd.DataFrame()\n","    for fold in CFG.trn_fold:\n","        _oof_df = train_loop(train, fold)\n","        oof_df = pd.concat([oof_df, _oof_df])\n","        print('+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')\n","        oof_df = oof_df.reset_index(drop=True)\n","        if not CFG.debug:\n","            oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl', protocol = 4)"]},{"cell_type":"code","execution_count":43,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1669781877487,"user":{"displayName":"Feng Qilong","userId":"09603490936825460639"},"user_tz":-480},"id":"6hpaS0ecmKpw"},"outputs":[],"source":["if CFG.wandb:\n","  wandb.finish()"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1669781877488,"user":{"displayName":"Feng Qilong","userId":"09603490936825460639"},"user_tz":-480},"id":"T7yp_mW7laSB","outputId":"a61a23d9-5b24-4032-f3fe-b75d4dec3d69"},"outputs":[{"name":"stdout","output_type":"stream","text":["(0.49239353943354386, [0.5206828528015025, 0.476696090454622, 0.46493775960974687, 0.49219390925825496, 0.5185058621330008, 0.4813447623441358])\n"]}],"source":["cv = get_score(oof_df[CFG.target_cols].values, oof_df[[f\"pred_{c}\" for c in CFG.target_cols]].values)\n","print(cv)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPdPNwqK5B3nI9KfoPWRu+j","machine_shape":"hm","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"042bc26178994d4fadd3bb0d7ebdaad1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04d720b4ccc1414fb8e439a2efe65f37":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0bc74cebb82c414db3b473ca2fd4c4f1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd4e5c615a474a258531b48a49f1184f","placeholder":"​","style":"IPY_MODEL_04d720b4ccc1414fb8e439a2efe65f37","value":"100%"}},"1268f2beb6ce4cc8899d5a82e16bb7c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e840e22885814101990b06fb4b3acb7b","max":367,"min":0,"orientation":"horizontal","style":"IPY_MODEL_79247e87089b4d319e1e5076d2fa9d29","value":367}},"1464849830154d74a16d4b0c56346464":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99a2821339094ed39aaeff1e412af5be","IPY_MODEL_cc2293455f89418b8089e07ac491574b","IPY_MODEL_820da2578b1e4634bc72f99f531df89f"],"layout":"IPY_MODEL_b5b135336de449569ba31345084f44c9"}},"1f0de55dbfc241bea6304991c6f8167a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2160dc67bf9243bfaab8d190e080f6cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"28a8fc3d8a5f4c3fa0e8a73a669dcaab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ffb08dd4296480180a494c556fbf4d9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30defcfb755848db8c0828ceb78c0ce4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3326acebbea443189aeb6139da42a98d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3440b0e704f348ec9af824f8dc29c4a3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"392e7609d8a74a4699128cdc0df9668f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5083106fac8047ffa4c40fad9fd6b45c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"61ac1ac30c2744b5a7e900c352ec62b7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6579b5dfab69442488128218447658fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3326acebbea443189aeb6139da42a98d","max":366,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f9a7c90026764dd2a7cf49194873e0f8","value":366}},"7005d4b808274b7c85dde7bd08df6ee9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_392e7609d8a74a4699128cdc0df9668f","max":366,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ef7d312d535f4da1926b4c61aa36b322","value":366}},"73f60470dbea40c0be460a45fb526e93":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79247e87089b4d319e1e5076d2fa9d29":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7d9777ccb696402c929a79905723bf25":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d02ea1a0b938483082a9e08bd1f5dbc4","IPY_MODEL_7005d4b808274b7c85dde7bd08df6ee9","IPY_MODEL_accefc9784b94e25a4c0154885b553fb"],"layout":"IPY_MODEL_73f60470dbea40c0be460a45fb526e93"}},"7e2ab252e2074792bb3b7db9d08dec3a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"820da2578b1e4634bc72f99f531df89f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0cd15c74c97491da98365bc9bf505a7","placeholder":"​","style":"IPY_MODEL_30defcfb755848db8c0828ceb78c0ce4","value":" 366/366 [02:12&lt;00:00,  2.80it/s]"}},"91a42b3a97674e359c1084d3aa510cc3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ffb08dd4296480180a494c556fbf4d9","placeholder":"​","style":"IPY_MODEL_2160dc67bf9243bfaab8d190e080f6cc","value":" 366/366 [05:46&lt;00:00,  2.78it/s]"}},"91b66c9d4c024cf3a595e6fcf7a19099":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9804037822044844932576e4bee1d1db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0bc74cebb82c414db3b473ca2fd4c4f1","IPY_MODEL_1268f2beb6ce4cc8899d5a82e16bb7c2","IPY_MODEL_a350ba65cb5b40e383e13a2a318e2503"],"layout":"IPY_MODEL_e29b17c5440c401ca683361192c86bed"}},"99a2821339094ed39aaeff1e412af5be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f0de55dbfc241bea6304991c6f8167a","placeholder":"​","style":"IPY_MODEL_5083106fac8047ffa4c40fad9fd6b45c","value":"100%"}},"a350ba65cb5b40e383e13a2a318e2503":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df3a0dd5662848b894124aafe0c1b3d9","placeholder":"​","style":"IPY_MODEL_28a8fc3d8a5f4c3fa0e8a73a669dcaab","value":" 367/367 [06:01&lt;00:00,  3.29it/s]"}},"a7c46cc8ac784b9e91958e5734add3c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bd44e8e3584f4fd1af565eadac329fae","IPY_MODEL_6579b5dfab69442488128218447658fe","IPY_MODEL_91a42b3a97674e359c1084d3aa510cc3"],"layout":"IPY_MODEL_042bc26178994d4fadd3bb0d7ebdaad1"}},"accefc9784b94e25a4c0154885b553fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_61ac1ac30c2744b5a7e900c352ec62b7","placeholder":"​","style":"IPY_MODEL_ee8ec12f1e05411d808096fa48c9f7d0","value":" 366/366 [05:58&lt;00:00,  2.67it/s]"}},"b5b135336de449569ba31345084f44c9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd44e8e3584f4fd1af565eadac329fae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91b66c9d4c024cf3a595e6fcf7a19099","placeholder":"​","style":"IPY_MODEL_d447ad55851043b0b56ff47d2ce754ca","value":"100%"}},"bd4e5c615a474a258531b48a49f1184f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc2293455f89418b8089e07ac491574b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_3440b0e704f348ec9af824f8dc29c4a3","max":366,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7e2ab252e2074792bb3b7db9d08dec3a","value":366}},"cc4122c7dab244a999cd03a2d4164118":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d02ea1a0b938483082a9e08bd1f5dbc4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed26737a317b42a8b7a6bd08558122b6","placeholder":"​","style":"IPY_MODEL_cc4122c7dab244a999cd03a2d4164118","value":"100%"}},"d0cd15c74c97491da98365bc9bf505a7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d447ad55851043b0b56ff47d2ce754ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df3a0dd5662848b894124aafe0c1b3d9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e29b17c5440c401ca683361192c86bed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e840e22885814101990b06fb4b3acb7b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed26737a317b42a8b7a6bd08558122b6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee8ec12f1e05411d808096fa48c9f7d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef7d312d535f4da1926b4c61aa36b322":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f9a7c90026764dd2a7cf49194873e0f8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
